{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 17:53:31.157740: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from bnpm import file_helpers, optimization\n",
    "import sklearn.utils.class_weight\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "import sklearn.linear_model\n",
    "import multiprocessing as mp\n",
    "\n",
    "import roicat.classification.classifier_util as cu\n",
    "import scipy.sparse\n",
    "import roicat\n",
    "import bnpm.h5_handling\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import warnings\n",
    "import umap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.offsetbox\n",
    "import json\n",
    "import os\n",
    "import natsort\n",
    "from roicat import helpers\n",
    "# from kymatio.torch import Scattering2D\n",
    "import gc\n",
    "import functools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_params = None # Path(r\"\")\n",
    "# directory_data = r'/Users/josh/analysis/outputs/ROICaT/classification/00_data_ingestion'\n",
    "directory_data = r'/Users/josh/analysis/outputs/ROICaT/classification/01_labels/feature_label_combo.npy'\n",
    "directory_save = r'/Users/josh/analysis/outputs/ROICaT/classification/02_classifier_train'\n",
    "testing = True\n",
    "save_ROIs = True\n",
    "save_latents = True\n",
    "\n",
    "\n",
    "# path_params = None # Path(r\"\")\n",
    "# # filepath_ROIs = r'/Users/josh/analysis/outputs/ROICaT/classification/01_labels/arr_ROIs.npy'\n",
    "# filepath_ROIs = None\n",
    "# filepath_latents = r'/Users/josh/analysis/outputs/ROICaT/classification/01_labels/arr_latents.npy'\n",
    "# filepath_labels = r'/Users/josh/analysis/outputs/ROICaT/classification/01_labels/arr_labels.npy'\n",
    "# testing = True\n",
    "# assert (filepath_ROIs is None) != (filepath_latents is None), 'Exactly one of filepath_ROIs or filepath_latents should be set'\n",
    "# assert Path(filepath_labels).exists(), 'File located at filepath_labels does not exist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_save = Path(directory_save)\n",
    "directory_save.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "labelingRun_interim = {}\n",
    "\n",
    "if path_params is not None:\n",
    "    try:\n",
    "        Path(str((directory_save).resolve())).mkdir(exist_ok=True, parents=True)\n",
    "        shutil.copy2(path_params, str(Path(directory_save) / Path(path_params).name));\n",
    "    except Exception as e:\n",
    "        print(f'JZ: Error copying params to {directory_save}')\n",
    "        print(e)\n",
    "tic = time.time()\n",
    "tictoc = {}\n",
    "tictoc['start'] = time.time() - tic\n",
    "\n",
    "params = file_helpers.json_load(str(Path(path_params).resolve())) if path_params is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %matplotlib notebook\n",
    "# # dir_allOuterFolders = str(Path('/Users/josh/analysis/data/ROICaT/classification/raw_images').resolve())\n",
    "# dir_allOuterFolders = str(Path('/Users/josh/analysis/data/ROICaT/classification/stat_s2p').resolve())\n",
    "\n",
    "# pathSuffixToStat = 'stat.npy'\n",
    "# pathSuffixToOps = 'ops.npy'\n",
    "\n",
    "# paths_allStat = test = helpers.find_paths(\n",
    "#     dir_outer=dir_allOuterFolders,\n",
    "#     reMatch=pathSuffixToStat,\n",
    "#     depth=4,\n",
    "# )\n",
    "# paths_allOps = test = helpers.find_paths(\n",
    "#     dir_outer=dir_allOuterFolders,\n",
    "#     reMatch=pathSuffixToOps,\n",
    "#     depth=4,\n",
    "# )\n",
    "\n",
    "# display(paths_allStat)\n",
    "# display(paths_allOps)\n",
    "\n",
    "# #Import data\n",
    "# data = roicat.data_importing.Data_suite2p(\n",
    "#     paths_statFiles=paths_allStat,\n",
    "#     paths_opsFiles=paths_allOps,\n",
    "#     um_per_pixel=2.0,\n",
    "#     new_or_old_suite2p='new',\n",
    "#     out_height_width=[36, 36],\n",
    "#     type_meanImg='meanImgE',\n",
    "#     verbose=True,\n",
    "# );\n",
    "# # Neural network embedding distances\n",
    "# roinet = roicat.ROInet.ROInet_embedder(\n",
    "#     device=roicat.util.helpers.set_device('cuda:0'),\n",
    "#     dir_networkFiles=r\"/Users/josh/analysis/models\",\n",
    "#     download_method=\"check_local_first\",\n",
    "#     download_url=\"https://osf.io/xwzhp/download\",\n",
    "#     download_hash=\"134b170242141c26b0adbd9e0fd80d0e\",\n",
    "#     forward_pass_version=\"head\",\n",
    "#     verbose=True,\n",
    "# )\n",
    "\n",
    "# roinet.generate_dataloader(\n",
    "#     ROI_images=data.ROI_images,\n",
    "#     um_per_pixel=data.um_per_pixel,\n",
    "#     pref_plot=False,\n",
    "#     batchSize_dataloader=8,\n",
    "#     pinMemory_dataloader=True,\n",
    "#     numWorkers_dataloader=mp.cpu_count(),\n",
    "#     persistentWorkers_dataloader=True,\n",
    "#     prefetchFactor_dataloader=2,    \n",
    "# );\n",
    "\n",
    "# # roicat.visualization.display_toggle_image_stack(roinet.ROI_images_rs)\n",
    "\n",
    "# roinet.generate_latents();\n",
    "\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass Through Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_label_combo = np.load(directory_data, allow_pickle=True)[()]\n",
    "# feature_label_combo[()]['embeddings']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Validation / Test Split Data, Hyperparameter Tune on Validation Set, and Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data...\n",
      "Creating X and y matrices for training data...\n",
      "Calculating class weights...\n",
      "Fitting model to data of dimensions: X: torch.Size([2938, 100]), y: (2938,)...\n",
      "Calculating tracker outputs and saving to /Users/josh/analysis/outputs/ROICaT/classification/02_classifier_train...\n",
      "Saving results:  /Users/josh/analysis/outputs/ROICaT/classification/02_classifier_train/results_training.csv /Users/josh/analysis/outputs/ROICaT/classification/02_classifier_train/results_timing.json\n",
      "self.tictoc={'start': 5.221366882324219e-05, 'loaded_data': 0.5959882736206055, 'splitted_data': 0.5976812839508057, 'completed_training_in_0': 1.6548023223876953}\n",
      "self.model={'coef': array([[ 5.61014886e-05, -9.70667940e-04, -6.22097357e-04,\n",
      "        -6.21056786e-04,  1.81241508e-04, -5.92208042e-04,\n",
      "         5.40390512e-04,  4.87894887e-04,  1.01062387e-03,\n",
      "         1.03974562e-03,  7.46187212e-04,  7.42438347e-04,\n",
      "         5.46096527e-04, -2.04601173e-04, -5.28011753e-05,\n",
      "         6.11551818e-04,  6.11413285e-04, -1.26807984e-04,\n",
      "        -8.38818114e-04,  1.23199317e-04,  6.01076684e-04,\n",
      "        -2.55137148e-04,  5.23040405e-04,  4.12123842e-04,\n",
      "         4.89085897e-04, -3.53715324e-04,  6.47159533e-05,\n",
      "        -1.05871016e-03,  1.79665148e-04,  3.50107288e-04,\n",
      "         6.87567839e-05,  1.39936540e-04,  3.98253558e-04,\n",
      "        -4.41793793e-04, -4.79516171e-04, -2.43760329e-04,\n",
      "         2.50512308e-04, -2.26555643e-04, -4.49227175e-05,\n",
      "         4.73006596e-04, -4.34644432e-04, -1.03058906e-03,\n",
      "        -6.20455375e-04, -1.09321755e-03, -7.75076057e-04,\n",
      "        -5.91129565e-04, -8.99941014e-05,  6.07744678e-04,\n",
      "        -1.06918705e-03, -3.92677557e-04,  1.76302788e-04,\n",
      "         2.18610613e-04, -1.31160338e-03,  1.69199042e-04,\n",
      "         1.25675095e-04,  7.92757331e-04, -3.52338289e-04,\n",
      "         3.90806842e-04,  3.60488095e-04,  1.27190115e-03,\n",
      "        -6.20971006e-04,  1.72129653e-03, -8.06175841e-04,\n",
      "         2.81621638e-03, -2.68490062e-04, -2.69901927e-03,\n",
      "         1.13370110e-05,  2.02229700e-03, -1.49011925e-04,\n",
      "        -9.82801650e-04,  3.19388187e-03, -9.77907820e-04,\n",
      "         1.55792439e-03, -8.95977814e-04,  1.33055232e-03,\n",
      "        -1.98627456e-03,  6.70875305e-03, -1.76804155e-03,\n",
      "        -4.08412791e-03, -2.51701004e-03, -3.15605495e-03,\n",
      "         6.59878491e-03,  1.03778045e-03, -2.83139947e-03,\n",
      "         3.90567575e-03, -5.27050132e-03, -7.16288753e-03,\n",
      "         9.02716145e-03, -8.38373231e-03,  2.47943614e-03,\n",
      "        -1.63390124e-02,  6.36703601e-04, -1.48281013e-03,\n",
      "        -1.33785829e-03, -1.92496989e-03, -9.52955749e-03,\n",
      "         2.27346647e-03,  8.98124432e-03,  5.20997363e-02,\n",
      "         7.91051016e-02]]), 'intercept': array([3.96537535])}\n",
      "   accuracy_training                           confusionMatrix_training  \\\n",
      "0           0.807692  [[0.8325391422736556, 0.21715452688904016], [0...   \n",
      "\n",
      "   accuracy_val                                confusionMatrix_val  \n",
      "0      0.783673  [[0.8061224489795918, 0.23877551020408164], [0...  \n"
     ]
    }
   ],
   "source": [
    "INTEGER_MAX = np.iinfo(np.int64(0).dtype).max\n",
    "\n",
    "# TODO: JZ, IMPLEMENT AS LOOP FOR OPTUNA FOR HYPERPARAMETER TUNING\n",
    "print('Splitting data...')\n",
    "# Create data splitting object for stratified sampling into train and test sets (as well as downsampling)\n",
    "data_split_val = cu.Datasplit(\n",
    "    features=feature_label_combo['latents'],\n",
    "    labels=feature_label_combo['labels'],\n",
    "    n_train=INTEGER_MAX,\n",
    "    test_size=0.2,\n",
    ")\n",
    "data_split_test = cu.Datasplit(\n",
    "    features=data_split_val.features_train,\n",
    "    labels=data_split_val.labels_train,\n",
    "    n_train=INTEGER_MAX,\n",
    "    test_size = 0.2/(1 - 0.2),\n",
    ")\n",
    "\n",
    "print('Creating X and y matrices for training data...')\n",
    "X_train = data_split_test.features_train\n",
    "y_train = data_split_test.labels_train\n",
    "\n",
    "X_val = data_split_val.features_val\n",
    "y_val = data_split_val.labels_val\n",
    "\n",
    "X_test = data_split_val.features_val\n",
    "y_test = data_split_val.labels_val\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "tictoc['loaded_data'] = time.time() - tic\n",
    "print('Calculating class weights...')\n",
    "num_classes = len(np.unique(feature_label_combo['labels']))\n",
    "class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(feature_label_combo['labels']), y=feature_label_combo['labels'])\n",
    "\n",
    "labels_train = y_train.reshape(-1) # np.stack([data_split.labels_train_subset]*latents_augmented.shape[1], axis=1).reshape(-1)\n",
    "features_train = X_train.reshape(-1, X_train.shape[-1]) # latents_augmented[data_split.features_train_subset].reshape(-1, latents_augmented.shape[2])\n",
    "\n",
    "labels_val = y_val.reshape(-1) # data_split.labels_val\n",
    "features_val = X_val.reshape(-1, X_val.shape[-1]) # latents_unaugmented[data_split.features_val]\n",
    "\n",
    "labels_test = y_test.reshape(-1) # data_split.labels_val\n",
    "features_test = X_test.reshape(-1, X_test.shape[-1]) # latents_unaugmented[data_split.features_val]\n",
    "\n",
    "n_train_actual = X_train.shape[0]\n",
    "n_val_actual = X_val.shape[0]\n",
    "n_test_actual = X_test.shape[0]\n",
    "\n",
    "tictoc['splitted_data'] = time.time() - tic\n",
    "\n",
    "print(f'Fitting model to data of dimensions: X: {X_train.shape}, y: {y_train.shape}...')\n",
    "# Create lenet model, associated optimizer, loss function, and training tracker\n",
    "model = sklearn.linear_model.LogisticRegression(\n",
    "   solver='lbfgs',\n",
    "   fit_intercept=True,\n",
    "   max_iter=10000,\n",
    "   C=1e5,\n",
    "   class_weight={iClassWeight:classWeight for iClassWeight, classWeight in enumerate(class_weights)},\n",
    "#    class_weight=class_weights,\n",
    ")\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "print(f'Calculating tracker outputs and saving to {directory_save}...')\n",
    "training_tracker = cu.TrainingTracker(\n",
    "    directory_save=directory_save,\n",
    "    class_weights=class_weights, # Class Weights\n",
    "    tictoc=tictoc, # Time Tracker\n",
    "    n_train_actual=n_train_actual,\n",
    "    model=({'coef':model.coef_, 'intercept':model.intercept_})\n",
    ")\n",
    "\n",
    "y_train_preds = model.predict(features_train).astype(int)\n",
    "y_train_true = labels_train\n",
    "y_val_preds = model.predict(features_val).astype(int)\n",
    "y_val_true = labels_val\n",
    "\n",
    "# Save training loop results from current epoch for training set\n",
    "training_tracker.add_accuracy(0, 'accuracy_training', y_train_true, y_train_preds) # Generating training loss\n",
    "training_tracker.add_confusion_matrix(0, 'confusionMatrix_training', y_train_true, y_train_preds) # Generating confusion matrix\n",
    "\n",
    "# Save training loop results from current epoch for validation set\n",
    "training_tracker.add_accuracy(0, 'accuracy_val', y_val_true, y_val_preds) # Generating validation accuracy\n",
    "training_tracker.add_confusion_matrix(0, 'confusionMatrix_val', y_val_true, y_val_preds) # Generating validation confusion matrix\n",
    "\n",
    "tictoc[f'completed_training_in_{0}'] = time.time() - tic\n",
    "\n",
    "training_tracker.save_results() # TODO: JZ, ADJUST RESULTS SAVING TO SAVE CONFUSION MATRICES AS NOT A DATAFRAME CSV\n",
    "training_tracker.print_results()\n",
    "\n",
    "model_save = {\n",
    "    'intercept_': model.intercept_,\n",
    "    'coef_': model.coef_,\n",
    "    'classes_': model.classes_,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifierTrainingRun_interim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/02_classifier_train.ipynb Cell 12\u001b[0m in \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/02_classifier_train.ipynb#Y130sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39msave(\u001b[39mstr\u001b[39m((Path(directory_save) \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmodel.npy\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mresolve()), model_save, allow_pickle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/02_classifier_train.ipynb#Y130sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m classifierTrainingRun_interim[\u001b[39m'\u001b[39m\u001b[39mparams_prespecified\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m params\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/02_classifier_train.ipynb#Y130sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mstr\u001b[39m((Path(directory_save) \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mclassifierTrainingRun_interim.pkl\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mresolve()), \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/02_classifier_train.ipynb#Y130sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     np\u001b[39m.\u001b[39msave(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/02_classifier_train.ipynb#Y130sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         file\u001b[39m=\u001b[39mf,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/02_classifier_train.ipynb#Y130sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         arr\u001b[39m=\u001b[39mclassifierTrainingRun_interim,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/02_classifier_train.ipynb#Y130sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         allow_pickle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/02_classifier_train.ipynb#Y130sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifierTrainingRun_interim' is not defined"
     ]
    }
   ],
   "source": [
    "np.save(str((Path(directory_save) / 'model.npy').resolve()), model_save, allow_pickle=True)\n",
    "with open(str((Path(directory_save) / 'classifierTrainingRun_interim.pkl').resolve()), 'wb') as f:\n",
    "    np.save(\n",
    "        file=f,\n",
    "        arr=classifierTrainingRun_interim,\n",
    "        allow_pickle=True\n",
    "    )\n",
    "\n",
    "print(f'Saved model fit results.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROICaT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
