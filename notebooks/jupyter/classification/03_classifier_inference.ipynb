{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from bnpm import file_helpers, optimization\n",
    "import sklearn.utils.class_weight\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "import sklearn.linear_model\n",
    "import multiprocessing as mp\n",
    "\n",
    "import roicat.classification.classifier_util as cu\n",
    "import scipy.sparse\n",
    "import roicat\n",
    "import bnpm.h5_handling\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_params = None # Path(r\"\")\n",
    "# filepath_ROIs = r'/Users/josh/analysis/outputs/ROICaT/classification/01_labels/arr_ROIs.npy'\n",
    "filepath_ROIs = None\n",
    "filepath_latents = r'/Users/josh/analysis/outputs/ROICaT/classification/01_labels/arr_latents.npy'\n",
    "filepath_model = r'/Users/josh/analysis/outputs/ROICaT/classification/02_classifier_train/model.npy'\n",
    "\n",
    "assert (filepath_ROIs is None) != (filepath_latents is None), 'Exactly one of filepath_ROIs or filepath_latents should be set'\n",
    "assert Path(filepath_model).exists(), 'File located at filepath_model does not exist'\n",
    "\n",
    "directory_save = '/Users/josh/analysis/outputs/ROICaT/classification/03_classifier_inference'\n",
    "testing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_ROIs = Path(filepath_ROIs) if filepath_ROIs else None\n",
    "filepath_latents = Path(filepath_latents) if filepath_latents else None\n",
    "filepath_model = Path(filepath_model)\n",
    "directory_save = Path(directory_save)\n",
    "directory_save.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "classifierInferenceRun_interim = {}\n",
    "\n",
    "if path_params is not None:\n",
    "    try:\n",
    "        Path(str((directory_save).resolve())).mkdir(exist_ok=True, parents=True)\n",
    "        shutil.copy2(path_params, str(Path(directory_save) / Path(path_params).name));\n",
    "    except Exception as e:\n",
    "        print(f'JZ: Error copying params to {directory_save}')\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "tictoc = {}\n",
    "tictoc['start'] = time.time() - tic\n",
    "\n",
    "params = file_helpers.json_load(str(Path(path_params).resolve())) if path_params is not None else None\n",
    "model = np.load(filepath_model, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devices available: []\n",
      "no GPU available. Using CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if params is None:\n",
    "    params = {\n",
    "        \"method\": \"simclr\",\n",
    "        \"device\": \"cuda:0\",\n",
    "        \"datatype\": \"raw_images\",\n",
    "        \"hyperparameters_split\": {\n",
    "            \"n_train\": 50000,\n",
    "            \"test_size\": 0.3\n",
    "        },\n",
    "        \"paths\": {\n",
    "            \"directory_github\": \"/Users/josh/analysis/github_repos/\",\n",
    "            \"directory_simclrModel\": \"/Users/josh/analysis//models\",\n",
    "            \"filepath_umapModel\": None,\n",
    "        },\n",
    "        \"hyperparameters_training_classifier\": {\n",
    "            \"num_transform_copies\": 80,\n",
    "            \"solver\": \"lbfgs\",\n",
    "            \"fit_intercept\": True,\n",
    "            \"max_iter\": 20000,\n",
    "            \"C\": 0.01,\n",
    "            \"tol\": 0.001,\n",
    "            \"simclrModel_download_url\": \"https://osf.io/xwzhp/download\",\n",
    "            \"simclrModel_download_hash\": \"134b170242141c26b0adbd9e0fd80d0e\"\n",
    "        },\n",
    "        \"run_umap\": True,\n",
    "    }\n",
    "\n",
    "roicat.util.helpers.set_device(params['device'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Datasets (and Pass Through Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "JZ: The suite2p params.json file must include paths.filename_rawImages for raw_images datatype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/03_classifier_inference.ipynb Cell 10\u001b[0m in \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/03_classifier_inference.ipynb#X65sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     data \u001b[39m=\u001b[39m roicat\u001b[39m.\u001b[39mdata_importing\u001b[39m.\u001b[39mData_suite2p(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/03_classifier_inference.ipynb#X65sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         paths_statFiles\u001b[39m=\u001b[39m[filepath_data_stat],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/03_classifier_inference.ipynb#X65sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         paths_opsFiles\u001b[39m=\u001b[39m[filepath_data_ops],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/03_classifier_inference.ipynb#X65sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         verbose\u001b[39m=\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mhyperparameters_data\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/03_classifier_inference.ipynb#X65sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/03_classifier_inference.ipynb#X65sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39melif\u001b[39;00m params[\u001b[39m'\u001b[39m\u001b[39mdatatype\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw_images\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/03_classifier_inference.ipynb#X65sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mfilename_rawImages\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params[\u001b[39m'\u001b[39m\u001b[39mpaths\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mJZ: The suite2p params.json file must include paths.filename_rawImages for raw_images datatype\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/03_classifier_inference.ipynb#X65sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     filepath_data_rawImages \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m((Path(params[\u001b[39m'\u001b[39m\u001b[39mpaths\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mdirectory_data\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m/\u001b[39m params[\u001b[39m'\u001b[39m\u001b[39mpaths\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mfilename_rawImages\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mresolve())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/notebooks/jupyter/classification/03_classifier_inference.ipynb#X65sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     sf \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39msparse\u001b[39m.\u001b[39mload_npz(filepath_data_rawImages)\n",
      "\u001b[0;31mAssertionError\u001b[0m: JZ: The suite2p params.json file must include paths.filename_rawImages for raw_images datatype"
     ]
    }
   ],
   "source": [
    "directory_model = str(Path(params['paths']['directory_model']).resolve()) if 'directory_model' in params['paths'] else None\n",
    "\n",
    "if params['datatype'] == \"stat_s2p\":\n",
    "    assert 'filename_stat' in params['paths'] and 'filename_ops' in params['paths'], 'JZ: The suite2p params.json file must include paths.filename_stat and paths.filename_ops for stat_s2p datatype'\n",
    "    filepath_data_stat = str((Path(params['paths']['directory_data']) / params['paths']['filename_stat']).resolve())\n",
    "    filepath_data_ops = str((Path(params['paths']['directory_data']) / params['paths']['filename_ops']).resolve())\n",
    "\n",
    "    # Create data importing object to import suite2p data\n",
    "    data = roicat.data_importing.Data_suite2p(\n",
    "        paths_statFiles=[filepath_data_stat],\n",
    "        paths_opsFiles=[filepath_data_ops],\n",
    "        um_per_pixel=params['hyperparameters_data']['um_per_pixel'],\n",
    "        new_or_old_suite2p=params['hyperparameters_data']['new_or_old_suite2p'],\n",
    "        out_height_width=params['hyperparameters_data']['out_height_width'],\n",
    "        type_meanImg=params['hyperparameters_data']['type_meanImg'],\n",
    "        FOV_images=params['hyperparameters_data']['FOV_images'],\n",
    "        verbose=params['hyperparameters_data']['verbose'],\n",
    "    )\n",
    "elif params['datatype'] == \"raw_images\":\n",
    "    assert 'filename_rawImages' in params['paths'], 'JZ: The suite2p params.json file must include paths.filename_rawImages for raw_images datatype'\n",
    "    filepath_data_rawImages = str((Path(params['paths']['directory_data']) / params['paths']['filename_rawImages']).resolve())\n",
    "\n",
    "    sf = scipy.sparse.load_npz(filepath_data_rawImages)\n",
    "\n",
    "    data = roicat.data_importing.Data_roicat(verbose=True)\n",
    "    data.set_ROI_images(ROI_images=[sf.A.reshape(sf.shape[0], 36, 36)], um_per_pixel=params['hyperparameters_data']['um_per_pixel'])\n",
    "else:\n",
    "    raise ValueError(f\"Invalid datatype for simclr: {params['datatype']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filepath_ROIs:\n",
    "    tictoc['imported_data'] = time.time() - tic\n",
    "\n",
    "    ROI_images_rescaled = [roicat.ROInet.ROInet_embedder.resize_ROIs(rois, params['hyperparameters_data']['um_per_pixel']) for rois in data.ROI_images]\n",
    "\n",
    "    # Initialize concatendated data\n",
    "    ROI_images_init = np.concatenate(data.ROI_images, axis=0).astype(np.float32)\n",
    "    ROI_images_init_rescaled = np.concatenate(ROI_images_rescaled, axis=0).astype(np.float32)\n",
    "\n",
    "    # Perform data cleaning\n",
    "    idx_violations = (np.isnan(ROI_images_init_rescaled.sum(axis=(1,2)))*1 + (np.sum(ROI_images_init_rescaled, axis=(1,2))==0)*1 + np.isnan(_labels_init)) != 0\n",
    "    print('Number of idx_violations: ', idx_violations.sum(), ' out of ', len(idx_violations), ' total ROIs.')\n",
    "    print('Located at: ', np.where(idx_violations)[0])\n",
    "    print('Discarding these ROIs...')\n",
    "\n",
    "    ROI_images_filt = ROI_images_init_rescaled[~idx_violations]\n",
    "\n",
    "    if testing:\n",
    "        ROI_images_filt = ROI_images_filt[:100]\n",
    "\n",
    "    classifierInferenceRun_interim['ROI_images_filt'] = ROI_images_filt\n",
    "\n",
    "    tictoc['cleaned_data'] = time.time() - tic\n",
    "\n",
    "\n",
    "    transforms_final_all = cu.get_transforms(params['hyperparameters_augmentations_all'], scripted=True)\n",
    "    dataset_all = roicat.ROInet.dataset_simCLR(\n",
    "            X=torch.as_tensor(ROI_images_filt, device='cpu', dtype=torch.float32),\n",
    "            y=torch.as_tensor(np.zeros((ROI_images_filt.shape[0])), device='cpu', dtype=torch.float32),\n",
    "            n_transforms=1,\n",
    "            class_weights=np.array([1]),\n",
    "            transform=transforms_final_all, # *Use WarpPoints\n",
    "            DEVICE='cpu',\n",
    "            dtype_X=torch.float32,\n",
    "        )\n",
    "    dataloader_all = torch.utils.data.DataLoader( \n",
    "            dataset_all,\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            pin_memory=False,\n",
    "            num_workers=0,#mp.cpu_count(),\n",
    "            persistent_workers=False,\n",
    "            prefetch_factor=2,\n",
    "    )\n",
    "\n",
    "    roinet = roicat.ROInet.ROInet_embedder(\n",
    "        device=params['device'],\n",
    "        dir_networkFiles=params['paths']['directory_simclrModel'],\n",
    "        download_method='check_local_first',\n",
    "        forward_pass_version='head',\n",
    "        download_url=params['hyperparameters_training_simclr']['simclrModel_download_url'],\n",
    "        download_hash=params['hyperparameters_training_simclr']['simclrModel_download_hash'],\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    print(f'Extracting transformed images from dataloaders, passing through roinet model, and saving to {directory_save}...')\n",
    "\n",
    "    features_all, _labels_all, _idx_all, _sample_all = cu.extract_with_dataloader(\n",
    "        dataloader_all,\n",
    "        model=roinet.net,\n",
    "        num_copies=1,\n",
    "        device=params['device'],\n",
    "    )\n",
    "\n",
    "    classifierInferenceRun_interim['features_all'] = features_all\n",
    "    print(f'Unaugmented run completed.')\n",
    "\n",
    "else:\n",
    "    features_all = np.load(filepath_latents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Previously Fit Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tictoc['loaded_data'] = time.time() - tic\n",
    "print('Calculating class weights...')\n",
    "\n",
    "tictoc['splitted_data'] = time.time() - tic\n",
    "\n",
    "# Create lenet model, associated optimizer, loss function, and training tracker\n",
    "model = sklearn.linear_model.LogisticRegression(\n",
    "   solver=params['hyperparameters_training_simclr']['solver'],\n",
    "   fit_intercept=params['hyperparameters_training_simclr']['fit_intercept'],\n",
    "   max_iter=params['hyperparameters_training_simclr']['max_iter'],\n",
    "   C=params['hyperparameters_training_simclr']['C'],\n",
    "\n",
    ")\n",
    "\n",
    "dct_model = np.load(filepath_model, allow_pickle=True)\n",
    "model.coef_ = dct_model[()]['coef_']\n",
    "model.intercept_ = dct_model[()]['intercept_']\n",
    "model.classes_ = dct_model[()]['classes_']\n",
    "predictions = model.predict(features_all)\n",
    "predictionProbas = model.predict_proba(features_all)\n",
    "\n",
    "tictoc[f'completed_training_in_{0}'] = time.time() - tic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(str((Path(directory_save) / 'labels_predicted.npy').resolve()), predictions, allow_pickle=True)\n",
    "np.save(str((Path(directory_save) / 'labels_predictedProbas.npy').resolve()), predictionProbas, allow_pickle=True)\n",
    "\n",
    "classifierInferenceRun_interim['params_prespecified'] = params\n",
    "with open(str((Path(directory_save) / 'classifierInferenceRun_interim.pkl').resolve()), 'wb') as f:\n",
    "    np.save(\n",
    "        file=f,\n",
    "        arr=classifierInferenceRun_interim,\n",
    "        allow_pickle=True\n",
    "    )\n",
    "\n",
    "print(f'Saved model fit results.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROICaT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
