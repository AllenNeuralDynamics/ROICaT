{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50622a4e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92846ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# widen jupyter notebook window\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:95% !important; }</style>\"))\n",
    "\n",
    "# check environment\n",
    "import os\n",
    "print(f'Conda Environment: ' + os.environ['CONDA_DEFAULT_ENV'])\n",
    "\n",
    "from platform import python_version\n",
    "print(f'python version: {python_version()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eb1fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import natsort\n",
    "\n",
    "import torch\n",
    "# from kymatio.torch import Scattering2D\n",
    "\n",
    "import gc\n",
    "import time\n",
    "import functools\n",
    "import multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a05452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "toc = {}\n",
    "toc['start'] = time.time() - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7a5c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_save = '/home/rich/Desktop/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bcc1a828",
   "metadata": {},
   "source": [
    "used for valerio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd0569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'paths': {\n",
    "#         'dir_github': r'/media/rich/Home_Linux_partition/github_repos/',  ## directory where ROICat is\n",
    "#         'dir_allOuterFolders': r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/20220117_email/Proximal_Dendrites\",  ## directory where directories containing below 'pathSuffixTo...' are\n",
    "#         'pathSuffixToStat': 'stat.npy',  ## path suffix to where the stat.npy file is\n",
    "#         'pathSuffixToOps': 'ops.npy',  ## path suffix to where the ops.npy file is\n",
    "#         'dir_save': r'/home/rich/Desktop/',  ## default: None. Directory to save output file to. If None then saves in dir_allOuterFolders.\n",
    "#         'filenamePrefix_save': None,  ##  default: None. Filename prefix to save results to. If None then just uses the dir_allOuterFolders.name.\n",
    "#     },\n",
    "#     'importing': {\n",
    "#         'data_verbose': True,  ## default: True. Whether to print out data importing information\n",
    "#         'out_height_width': [72, 72],  ## default: [36,36]. Height and width of small cropped output images of each ROI. Check how large your ROIs are in pixels.\n",
    "#         'max_footprint_width': 1025,  ## default: 1025. Maximum length of a spatial footprint. If you get an error during importing, try increasing this value.\n",
    "#         'type_meanImg': 'meanImgE',  ## default: 'meanImgE'. Type of mean image to use for normalization. This is just a field in the ops.npy file.\n",
    "#         'um_per_pixel': 1.0,  ## default: 1.0. Number of microns per pixel for the imaging dataset. Doesn't need to be exact. Used for resizing the ROIs. Check the images of the resized ROIs to tweak.\n",
    "#         'new_or_old_suite2p': 'new',  ## default: 'new'. If using suite2p, this specifices whether the stat.npy file is in the old MATLAB format or new Python format.\n",
    "#         'images': None,  ## default: None. Set to None if you want to use the images extracted from Suite2p\n",
    "#         'import_workers': -1, ## default: -1. Number of workers to use for importing. Set to -1 to use all available workers.\n",
    "#     },\n",
    "#     'alignment': {\n",
    "#         'do_phaseCorrReg': True,  ## default: True. If you are having issues with alignment due to big movements of the FOV. Try setting this to False.\n",
    "#         'session_template': 0.5,  ## default: 0.5. Which session to use as a registration template. If input is float (ie 0.0, 0.5, 1.0, etc.), then it is the fractional position of the session to use; if input is int (ie 1, 2, 3), then it is the index of the session to use (0-indexed)\n",
    "#         'phaseCorr': {\n",
    "#             'freq_highPass': 0.01,  ## default: 0.01. Spatial frequency upper-bound cut-off to use for phase correlation. Units in fraction of the height of the FOV. Spatial frequencies correlations higher than this will be set to zero.\n",
    "#             'freq_lowPass': 0.3,  ## default: 0.3. Spatial frequency lower-bound cut-off to use for phase correlation. Units in fraction of the height of the FOV. Spatial frequencies correlations lower than this will be set to zero.\n",
    "#         },\n",
    "#         'method': 'createOptFlow_DeepFlow',  ## default: 'createOptFlow_DeepFlow'. Method to use for creating optical flow.\n",
    "#         'kwargs_method': None,  ## default: None. Keyword arguments to pass to the cv2 optical flow method.\n",
    "#         'use_CLAHE': False,  ## default: False. Whether or not to use 'Contrast Limited Adaptive Histogram Equalization'. Useful if params['importing']['type_meanImg'] is not a contrast enhanced image (like 'meanImgE' in Suite2p)\n",
    "#         'return_sparse': True,  ## default: True. Whether to return a sparse matrix (True) or a dense matrix (False).\n",
    "#         'normalize': True,  ## default: True. If True, normalize the spatial footprints to have a sum of 1.\n",
    "#     },\n",
    "#     'blurring': {\n",
    "#         'kernel_halfWidth': 5.0,  ## default: 2.0. Half-width of the cosine kernel used for blurring. Set value based on how much you think the ROIs move from session to session.\n",
    "#         'plot_kernel': False,  ## default: False. Whether to plot the kernel used for blurring.\n",
    "#     },\n",
    "#     'ROInet': {\n",
    "#         'device': 'cuda:0',  ## default: 'cuda:0'. Device to use for ROInet. Recommend using a GPU.\n",
    "#         'hash_dict_true': {\n",
    "#             'params': ('params.json', '68cf1bd47130f9b6d4f9913f86f0ccaa'),\n",
    "#             'model': ('model.py', '61c85529b7aa33e0dfadb31ee253a7e1'),\n",
    "#             'state_dict': ('ConvNext_tiny__1_0_best__simCLR.pth', '3287e001ff28d07ada2ae70aa7d0a4da'),\n",
    "#         },\n",
    "#         'dir_networkFiles': '/home/rich/Downloads/ROInet',  ## local directory where network files are stored\n",
    "#         'download_from_gDrive': 'check_local_first',  ## default: 'check_local_first'. Whether to download the network files from Google Drive or to use the local files.\n",
    "#         'gDriveID': '1D2Qa-YUNX176Q-wgboGflW0K6un7KYeN',  ## default: '1FCcPZUuOR7xG-hdO6Ei6mx8YnKysVsa8'. Google Drive ID of the network files.\n",
    "#         'forward_pass_version': 'latent', # default: 'latent'. Leave as 'latent' for most things. Can be 'latent' (full pass through network), 'head' (output of the head layers), or 'base' (pass through just base layers)\n",
    "#         'verbose': True,  ## default: True. Whether to print out ROInet information.\n",
    "#         'pref_plot': False,  ## default: False. Whether to plot the ROI and the normalized ROI.\n",
    "#         'batchSize_dataloader': 8,  ## default: 8. Number of images to use for each batch.\n",
    "#         'pinMemory_dataloader': True,  ## default: True. Whether to pin the memory of the dataloader.\n",
    "#         'persistentWorkers_dataloader': True,  ## default: True. Whether to use persistent workers for the dataloader.\n",
    "#         'prefetchFactor_dataloader': 2,  ## default: 2. Number of prefetch factors to use for the dataloader.\n",
    "#     },\n",
    "#     'SWT': {\n",
    "#         'kwargs_Scattering2D': {'J': 2, 'L': 2},  ## default: {'J': 2, 'L': 2}. Keyword arguments to pass to the kymatio Scattering2D function.\n",
    "#         'device': 'cuda:0',  ## default: 'cuda:0'. Device to use for SWT. Recommend using a GPU.\n",
    "#     }, \n",
    "#     'similarity': {\n",
    "#         'spatialFootprint_maskPower': 0.8,  ## default: 1.0. This determines the power to take the ROI mask images to. Higher for more dependent on brightness, lower for more dependent on binary overlap.\n",
    "#         'n_workers': -1,  ## default: -1. Number of workers to use for similarity. Set to -1 to use all available workers.\n",
    "#         'block_height': 128,  ## default: 64. Maximum height of the FOV block bins to use for pairwise ROI similarity calculations. Use smaller values (16-64) if n_sessions is large (<12), else keep around (64-128)\n",
    "#         'block_width': 128,  ## default: 64. Maximum width of the FOV block bins to use for pairwise ROI similarity calculations. Use smaller values (16-64) if n_sessions is large (<12), else keep around (64-128)\n",
    "#         'algorithm_nearestNeigbors_spatialFootprints': 'brute',  ## default: 'brute'. Algorithm to use for nearest neighbors.\n",
    "#         'verbose': True,  ## default: True. Whether to print out similarity information.\n",
    "#         'normalization': {\n",
    "#             'k_max': 4000,  ## default: 4000. Maximum kNN distance to use for building a distribution of pairwise similarities for each ROI.\n",
    "#             'k_min': 150,  ## default: 150. Set around n_sessions*10. Minimum kNN distance to use for building a distribution of pairwise similarities for each ROI. \n",
    "#             'algo_NN': 'kd_tree',  ## default: 'kd_tree'. Algorithm to use for the nearest neighbors search across positional distances of different ROIs center positions. 'kd_tree' seems to be fastest. See sklearn nearest neighbor documentation for details.\n",
    "#             'device': 'cuda:0',  ## default: 'cpu'. Device to use for the cosine similarity comparisons. Pytorch device.\n",
    "#         },\n",
    "#     },\n",
    "#     ## Cluster\n",
    "#     'clustering': {\n",
    "#         'plot_pref': True,\n",
    "#         'auto_pruning':{\n",
    "#             'n_bins': 50,  ## default: 50. Number of bins to use for estimating the distributions for 'different' and 'same' pairwise similarities\n",
    "#             'find_parameters_automatically': True,  ## default: True. Use optuna automatic parameter searching to find the best values for 'kwargs_makeConjunctiveDistanceMatrix'\n",
    "#             'n_jobs': -1, ## default: 2. Number of jobs to use for the optuna parameter search. Large values or -1 can result in high memory usage.\n",
    "#             'kwargs_findParameters': {\n",
    "#                 'n_patience': 100,\n",
    "#                 'tol_frac': 0.05,\n",
    "#                 'max_trials': 350,\n",
    "#                 'max_duration': 60*10,\n",
    "#                 'verbose': False,\n",
    "#             },\n",
    "#             'bounds_findParameters': {\n",
    "#                 'power_SF': (0.3, 2),\n",
    "#                 'power_NN': (0.2, 2),\n",
    "#                 'power_SWT': (0.1, 1),\n",
    "#                 'p_norm': (-5, 5),\n",
    "#                 'sig_NN_kwargs_mu': (0, 0.5),\n",
    "#                 'sig_NN_kwargs_b': (0.05, 2),\n",
    "#                 'sig_SWT_kwargs_mu': (0, 0.5),\n",
    "#                 'sig_SWT_kwargs_b': (0.05, 2),\n",
    "#             },\n",
    "#         },\n",
    "#         'method': 'auto',  ## default: 'auto'. Can be 'hungarian', 'hdbscan', or 'auto'. If 'auto', then if n_sessions >=8 'hdbscan' will be used.\n",
    "#         'hdbscan':{  ## Used only if 'method' is 'hdbscan'\n",
    "#             'min_cluster_size': 2,  ## default: 2. Best practice is to keep at 2 because issues can occur otherwise. Just manually throw out clusters with fewer ROIs if needed.\n",
    "#             'alpha': 0.999,  ## default: 0.999. Use slightly smaller values (~0.8) if you want bigger less conservative clusters. See hdbscan documentation: https://hdbscan.readthedocs.io/en/latest/parameter_selection.html\n",
    "#             'd_clusterMerge': None,  ## default: None. Distance (mixed conjunctive distance) at which all samples less than this far apart are joined in clusters. If None, then set to mean + 1.0 std of the distribution. See 'cluster_selection_epsilon' in hdbscan documentation: https://hdbscan.readthedocs.io/en/latest/parameter_selection.html\n",
    "#             'cluster_selection_method': 'leaf',  ## default: 'leaf'. 'leaf' is better for smaller homogeneous clusters, 'eom' is better for larger clusters of various densities. See hdbscan documentation: https://hdbscan.readthedocs.io/en/latest/parameter_selection.html\n",
    "#             'split_intraSession_clusters': True,  ## default: True. Splits up clusters with multiple ROIs from the same session into multiple clusters.\n",
    "#             'd_step': 0.03,  ## default: 0.03. Size of steps to take when splitting clusters with multiple ROIs from the same session. Smaller values give higher quality clusters.\n",
    "#             'discard_failed_pruning': True,  ## default: Failsafe. If the splitting doesn't work for whatever reason, then just set all violating clusters to label=-1.\n",
    "#             'n_iter_violationCorrection': 5,  ## default: 5. Number of times to iterate a correcting process to improve clusters. Warning: This can increase run time linearly for large datasets. Typically converges after around 5 iterations. If n_sessions is large (>30), consider increasing.\n",
    "#         },\n",
    "#         'hungarian': {\n",
    "#             'thresh_cost': 0.95, ## default: 0.95. Threshold distance at which all clusters larger than this are discarded. Note that typically no change will occur after values > d_cutoff.\n",
    "#         },\n",
    "#     },\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3320975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'paths': {\n",
    "        'dir_allOuterFolders': r\"/media/rich/bigSSD/downloads_tmp/NN9\",  ## directory where directories containing below 'pathSuffixTo...' are\n",
    "        'pathSuffixToStat': 'stat.npy',  ## path suffix to where the stat.npy file is\n",
    "        'pathSuffixToOps': 'ops.npy',  ## path suffix to where the ops.npy file is\n",
    "        'dir_save': r'/home/rich/Desktop/',  ## default: None. Directory to save output file to. If None then saves in dir_allOuterFolders.\n",
    "        'filenamePrefix_save': None,  ##  default: None. Filename prefix to save results to. If None then just uses the dir_allOuterFolders.name.\n",
    "    },\n",
    "    'importing': {\n",
    "        'data_verbose': True,  ## default: True. Whether to print out data importing information\n",
    "        'out_height_width': [36, 36],  ## default: [36,36]. Height and width of small cropped output images of each ROI. Check how large your ROIs are in pixels.\n",
    "        'type_meanImg': 'meanImgE',  ## default: 'meanImgE'. Type of mean image to use for normalization. This is just a field in the ops.npy file.\n",
    "        'um_per_pixel': 1.0,  ## default: 1.0. Number of microns per pixel for the imaging dataset. Doesn't need to be exact. Used for resizing the ROIs. Check the images of the resized ROIs to tweak.\n",
    "        'new_or_old_suite2p': 'new',  ## default: 'new'. If using suite2p, this specifices whether the stat.npy file is in the old MATLAB format or new Python format.\n",
    "        'import_workers': -1, ## default: -1. Number of workers to use for importing. Set to -1 to use all available workers.\n",
    "    },\n",
    "    'alignment': {\n",
    "        'do_phaseCorrReg': True,  ## default: True. If you are having issues with alignment due to big movements of the FOV. Try setting this to False.\n",
    "        'session_template': 0.5,  ## default: 0.5. Which session to use as a registration template. If input is float (ie 0.0, 0.5, 1.0, etc.), then it is the fractional position of the session to use; if input is int (ie 1, 2, 3), then it is the index of the session to use (0-indexed)\n",
    "        'use_CLAHE': True,  ## default: False. Whether or not to use 'Contrast Limited Adaptive Histogram Equalization'. Useful if params['importing']['type_meanImg'] is not a contrast enhanced image (like 'meanImgE' in Suite2p)\n",
    "        'CLAHE_nGrid': 10,  ## default 10. Unsed if 'use_CLAHE' is False. Defines how many blocks to split the FOV into to normalize the local contrast. See openCV's clahe function. Larger means more CLAHE.\n",
    "        'phaseCorr': {\n",
    "            'freq_highPass': 0.01,  ## default: 0.01. Spatial frequency upper-bound cut-off to use for phase correlation. Units in fraction of the height of the FOV. Spatial frequencies correlations higher than this will be set to zero.\n",
    "            'freq_lowPass': 0.2,  ## default: 0.3. Spatial frequency lower-bound cut-off to use for phase correlation. Units in fraction of the height of the FOV. Spatial frequencies correlations lower than this will be set to zero.\n",
    "            'template_method': 'sequential',  # default: 'sequential'. Either 'sequential' or 'image'. 'sequential' is better if there is significant drift over sessions. If 'sequential', then pcr.register(template=idx) where idx is the index of the image you want the shifts to be relative to. If 'image', then idx is FOVs[idx].\n",
    "        },\n",
    "        'nonrigid':{\n",
    "            'method': 'createOptFlow_DeepFlow',  ## default: 'createOptFlow_DeepFlow'. Method to use for creating optical flow. 'calcOpticalFlowFarneback' and 'createOptFlow_DeepFlow' available.\n",
    "            'kwargs_method': None,  ## default: None. Keyword arguments to pass to the cv2 optical flow method.\n",
    "            'template_method': 'sequential',  ## default: 'image'. Either 'sequential' or 'image'. 'sequential' is better if there is significant drift over sessions.\n",
    "            'return_sparse': True,  ## default: True. Whether to return a sparse matrix (True) or a dense matrix (False).\n",
    "            'normalize': True,  ## default: True. If True, normalize the spatial footprints to have a sum of 1.\n",
    "        },\n",
    "    },\n",
    "    'blurring': {\n",
    "        'kernel_halfWidth': 2.0,  ## default: 2.0. Half-width of the cosine kernel used for blurring. Set value based on how much you think the ROIs move from session to session.\n",
    "        'plot_kernel': False,  ## default: False. Whether to plot the kernel used for blurring.\n",
    "    },\n",
    "    'ROInet': {\n",
    "        'device': 'cuda:0',  ## default: 'cuda:0'. Device to use for ROInet. Recommend using a GPU.\n",
    "        'dir_networkFiles': '/home/rich/Downloads/ROInet',  ## local directory where network files are stored\n",
    "        'download_method': 'check_local_first',  ## default: 'check_local_first'. Whether to download the network files from Google Drive or to use the local files.\n",
    "        'download_url': 'https://osf.io/x3fd2/download',  ## default: 'https://osf.io/x3fd2/download'. URL of the network files.\n",
    "        'download_hash': '7a5fb8ad94b110037785a46b9463ea94', ## default: '7a5fb8ad94b110037785a46b9463ea94'. MD5 hash of the network files .zip file.\n",
    "        'forward_pass_version': 'latent', # default: 'latent'. Leave as 'latent' for most things. Can be 'latent' (full pass through network), 'head' (output of the head layers), or 'base' (pass through just base layers)\n",
    "        'verbose': True,  ## default: True. Whether to print out ROInet information.\n",
    "        'pref_plot': False,  ## default: False. Whether to plot the ROI and the normalized ROI.\n",
    "        'batchSize_dataloader': 8,  ## default: 8. Number of images to use for each batch.\n",
    "        'pinMemory_dataloader': True,  ## default: True. Whether to pin the memory of the dataloader.\n",
    "        'persistentWorkers_dataloader': True,  ## default: True. Whether to use persistent workers for the dataloader.\n",
    "        'prefetchFactor_dataloader': 2,  ## default: 2. Number of prefetch factors to use for the dataloader.\n",
    "    },\n",
    "    'SWT': {\n",
    "        'kwargs_Scattering2D': {'J': 2, 'L': 2},  ## default: {'J': 2, 'L': 2}. Keyword arguments to pass to the kymatio Scattering2D function.\n",
    "        'device': 'cuda:0',  ## default: 'cuda:0'. Device to use for SWT. Recommend using a GPU.\n",
    "    }, \n",
    "    'similarity': {\n",
    "        'spatialFootprint_maskPower': 1.0,  ## default: 1.0. This determines the power to take the ROI mask images to. Higher for more dependent on brightness, lower for more dependent on binary overlap.\n",
    "        'n_workers': -1,  ## default: -1. Number of workers to use for similarity. Set to -1 to use all available workers.\n",
    "        'block_height': 128,  ## default: 64. Maximum height of the FOV block bins to use for pairwise ROI similarity calculations. Use smaller values (16-64) if n_sessions is large (<12), else keep around (64-128)\n",
    "        'block_width': 128,  ## default: 64. Maximum width of the FOV block bins to use for pairwise ROI similarity calculations. Use smaller values (16-64) if n_sessions is large (<12), else keep around (64-128)\n",
    "        'algorithm_nearestNeigbors_spatialFootprints': 'brute',  ## default: 'brute'. Algorithm to use for nearest neighbors.\n",
    "        'verbose': True,  ## default: True. Whether to print out similarity information.\n",
    "        'normalization': {\n",
    "            'k_max': 4000,  ## default: 4000. Maximum kNN distance to use for building a distribution of pairwise similarities for each ROI.\n",
    "            'k_min': 150,  ## default: 150. Set around n_sessions*10. Minimum kNN distance to use for building a distribution of pairwise similarities for each ROI. \n",
    "            'algo_NN': 'kd_tree',  ## default: 'kd_tree'. Algorithm to use for the nearest neighbors search across positional distances of different ROIs center positions. 'kd_tree' seems to be fastest. See sklearn nearest neighbor documentation for details.\n",
    "            'device': 'cuda:0',  ## default: 'cpu'. Device to use for the cosine similarity comparisons. Pytorch device.\n",
    "        },\n",
    "    },\n",
    "    ## Cluster\n",
    "    'clustering': {\n",
    "        'plot_pref': True,\n",
    "        'auto_pruning':{\n",
    "            'n_bins': 50,  ## default: 50. Number of bins to use for estimating the distributions for 'different' and 'same' pairwise similarities\n",
    "            'find_parameters_automatically': True,  ## default: True. Use optuna automatic parameter searching to find the best values for 'kwargs_makeConjunctiveDistanceMatrix'\n",
    "            'n_jobs': -1, ## default: 2. Number of jobs to use for the optuna parameter search. Large values or -1 can result in high memory usage.\n",
    "            'kwargs_findParameters': {\n",
    "                'n_patience': 100,\n",
    "                'tol_frac': 0.05,\n",
    "                'max_trials': 350,\n",
    "                'max_duration': 60*10,\n",
    "                'verbose': False,\n",
    "            },\n",
    "            'bounds_findParameters': {\n",
    "                'power_SF': (0.3, 2),\n",
    "                'power_NN': (0.2, 2),\n",
    "                'power_SWT': (0.1, 1),\n",
    "                'p_norm': (-5, 5),\n",
    "                'sig_NN_kwargs_mu': (0, 0.5),\n",
    "                'sig_NN_kwargs_b': (0.05, 2),\n",
    "                'sig_SWT_kwargs_mu': (0, 0.5),\n",
    "                'sig_SWT_kwargs_b': (0.05, 2),\n",
    "            },\n",
    "        },\n",
    "        'stringency': 1.0,  ## default: 1.0. Change this value to make the clustering more or less stringent how ROIs are included in a cluster Value changes the distance_cutoff used in the pruning process.\n",
    "        'method': 'auto',  ## default: 'auto'. Can be 'hungarian', 'hdbscan', or 'auto'. If 'auto', then if n_sessions >=8 'hdbscan' will be used.\n",
    "        'hdbscan':{  ## Used only if 'method' is 'hdbscan'\n",
    "            'min_cluster_size': 2,  ## default: 2. Best practice is to keep at 2 because issues can occur otherwise. Just manually throw out clusters with fewer ROIs if needed.\n",
    "            'alpha': 0.999,  ## default: 0.999. Use slightly smaller values (~0.8) if you want bigger less conservative clusters. See hdbscan documentation: https://hdbscan.readthedocs.io/en/latest/parameter_selection.html\n",
    "            'd_clusterMerge': None,  ## default: None. Distance (mixed conjunctive distance) at which all samples less than this far apart are joined in clusters. If None, then set to mean + 1.0 std of the distribution. See 'cluster_selection_epsilon' in hdbscan documentation: https://hdbscan.readthedocs.io/en/latest/parameter_selection.html\n",
    "            'cluster_selection_method': 'leaf',  ## default: 'leaf'. 'leaf' is better for smaller homogeneous clusters, 'eom' is better for larger clusters of various densities. See hdbscan documentation: https://hdbscan.readthedocs.io/en/latest/parameter_selection.html\n",
    "            'split_intraSession_clusters': True,  ## default: True. Splits up clusters with multiple ROIs from the same session into multiple clusters.\n",
    "            'd_step': 0.01,  ## default: 0.03. Size of steps to take when splitting clusters with multiple ROIs from the same session. Smaller values give higher quality clusters.\n",
    "            'discard_failed_pruning': True,  ## default: Failsafe. If the splitting doesn't work for whatever reason, then just set all violating clusters to label=-1.\n",
    "            'n_iter_violationCorrection': 6,  ## default: 5. Number of times to iterate a correcting process to improve clusters. Warning: This can increase run time linearly for large datasets. Typically converges after around 5 iterations. If n_sessions is large (>30), consider increasing.\n",
    "        },\n",
    "        'hungarian': {\n",
    "            'thresh_cost': 0.6, ## default: 0.95. Threshold distance at which all clusters larger than this are discarded. Note that typically no change will occur after values > d_cutoff.\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f1e6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import roicat\n",
    "from roicat import helpers, data_importing, ROInet\n",
    "from roicat.tracking import alignment, blurring, clustering, scatteringWaveletTransformer, similarity_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a34177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_all = [helpers.deep_update_dict(params, ['paths', 'dir_allOuterFolders'], val) for val in [\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/Sofia_ROIs/Data for Rich/SS33/\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/Sofia_ROIs/Data for Rich/SS33/\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/Sofia_ROIs/Data for Rich/SS37/\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/Sofia_ROIs/Data for Rich/SS37/\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/Sofia_ROIs/Data for Rich/SS40/\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/Sofia_ROIs/Data for Rich/SS40/\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/Sofia_ROIs/Data for Rich/SS40/\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/Sofia_ROIs/Data for Rich/SS40/\",\n",
    "# ]]\n",
    "\n",
    "# params_all = [helpers.deep_update_dict(params_all[ii], ['paths', 'pathSuffixToStat'], val) for ii,val in enumerate([\n",
    "#         r\"Slice02/stat.npy\",\n",
    "#         r\"Slice06/stat.npy\",\n",
    "#         r\"Slice02/stat.npy\",\n",
    "#         r\"Slice06/stat.npy\",\n",
    "#         r\"Slice01/stat.npy\",\n",
    "#         r\"Slice02/stat.npy\",\n",
    "#         r\"Slice05/stat.npy\",\n",
    "#         r\"Slice06/stat.npy\",\n",
    "# ])]\n",
    "\n",
    "# params_all = [helpers.deep_update_dict(params_all[ii], ['paths', 'pathSuffixToOps'], val) for ii,val in enumerate([\n",
    "#         r\"Slice02/ops.npy\",\n",
    "#         r\"Slice06/ops.npy\",\n",
    "#         r\"Slice02/ops.npy\",\n",
    "#         r\"Slice06/ops.npy\",\n",
    "#         r\"Slice01/ops.npy\",\n",
    "#         r\"Slice02/ops.npy\",\n",
    "#         r\"Slice05/ops.npy\",\n",
    "#         r\"Slice06/ops.npy\",\n",
    "# ])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec58b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_all = [helpers.deep_update_dict(params, ['clustering', 'stringency'], val) for val in [\n",
    "    0.2,\n",
    "    0.4,\n",
    "    0.6,\n",
    "    0.8,\n",
    "    1.0,\n",
    "    1.2,\n",
    "    1.4,\n",
    "    1.6,\n",
    "    1.8,\n",
    "]]\n",
    "\n",
    "# params_all = [helpers.deep_update_dict(params_all[ii], ['paths', 'pathSuffixToStat'], val) for ii,val in enumerate([\n",
    "#         r\"Slice02/stat.npy\",\n",
    "#         r\"Slice06/stat.npy\",\n",
    "#         r\"Slice02/stat.npy\",\n",
    "#         r\"Slice06/stat.npy\",\n",
    "#         r\"Slice01/stat.npy\",\n",
    "#         r\"Slice02/stat.npy\",\n",
    "#         r\"Slice05/stat.npy\",\n",
    "#         r\"Slice06/stat.npy\",\n",
    "# ])]\n",
    "\n",
    "# params_all = [helpers.deep_update_dict(params_all[ii], ['paths', 'pathSuffixToOps'], val) for ii,val in enumerate([\n",
    "#         r\"Slice02/ops.npy\",\n",
    "#         r\"Slice06/ops.npy\",\n",
    "#         r\"Slice02/ops.npy\",\n",
    "#         r\"Slice06/ops.npy\",\n",
    "#         r\"Slice01/ops.npy\",\n",
    "#         r\"Slice02/ops.npy\",\n",
    "#         r\"Slice05/ops.npy\",\n",
    "#         r\"Slice06/ops.npy\",\n",
    "# ])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9725042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_all = [params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2e1e69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for params in params_all:\n",
    "    # %matplotlib notebook\n",
    "\n",
    "\n",
    "    dir_allOuterFolders = str(Path(params['paths']['dir_allOuterFolders']).resolve())\n",
    "\n",
    "\n",
    "    pathSuffixToStat = params['paths']['pathSuffixToStat']\n",
    "    pathSuffixToOps = params['paths']['pathSuffixToOps']\n",
    "\n",
    "    paths_allStat = test = helpers.find_paths(\n",
    "        dir_outer=dir_allOuterFolders,\n",
    "        reMatch=pathSuffixToStat,\n",
    "        depth=4,\n",
    "    )[:2]\n",
    "    paths_allOps = test = helpers.find_paths(\n",
    "        dir_outer=dir_allOuterFolders,\n",
    "        reMatch=pathSuffixToOps,\n",
    "        depth=4,\n",
    "    )[:2]\n",
    "\n",
    "    print(display(paths_allStat))\n",
    "    print(display(paths_allOps))\n",
    "\n",
    "    #Import data\n",
    "    data = data_importing.Data_suite2p(\n",
    "        paths_statFiles=paths_allStat,\n",
    "        paths_opsFiles=paths_allOps,\n",
    "        um_per_pixel=params['importing']['um_per_pixel'],    \n",
    "        new_or_old_suite2p=params['importing']['new_or_old_suite2p'],\n",
    "        \n",
    "        out_height_width=params['importing']['out_height_width'],\n",
    "        type_meanImg=params['importing']['type_meanImg'],\n",
    "        \n",
    "        verbose=params['importing']['data_verbose'],\n",
    "    );\n",
    "\n",
    "    # roicat.visualization.display_toggle_image_stack(data.FOV_images)\n",
    "\n",
    "    toc['import_data'] = time.time() - tic\n",
    "\n",
    "\n",
    "    # Alignment\n",
    "    FOV_images = [alignment.clahe(im, grid_size=params['alignment']['CLAHE_nGrid'], clipLimit=np.inf, normalize=True) for im in data.FOV_images[:]] if params['alignment']['use_CLAHE'] else data.FOV_images\n",
    "    st = params['alignment']['session_template']\n",
    "    idx_st = int(st * data.n_sessions) if type(st) is float else st\n",
    "\n",
    "    if params['alignment']['do_phaseCorrReg']:\n",
    "        if params['alignment']['phaseCorr']['template_method'] == 'image':\n",
    "            template = FOV_images[idx_st] \n",
    "        if params['alignment']['phaseCorr']['template_method'] == 'sequential':\n",
    "            template = idx_st\n",
    "            \n",
    "        pcr = alignment.PhaseCorrelation_registration()\n",
    "\n",
    "        pcr.set_spectral_mask(\n",
    "            freq_highPass=params['alignment']['phaseCorr']['freq_highPass'],\n",
    "            freq_lowPass=params['alignment']['phaseCorr']['freq_lowPass'],\n",
    "            im_shape=(data.FOV_height, data.FOV_width)\n",
    "        )\n",
    "\n",
    "        pcr.register(\n",
    "            template=template,\n",
    "            ims_moving=FOV_images,\n",
    "            template_method=params['alignment']['phaseCorr']['template_method'],\n",
    "        );\n",
    "        \n",
    "        FOV_images_forAligner = pcr.ims_registered\n",
    "        shifts = pcr.shifts\n",
    "        \n",
    "        roicat.visualization.display_toggle_image_stack(pcr.ims_registered[:])\n",
    "    else:\n",
    "        FOV_images_forAligner = FOV_images\n",
    "        shifts = None\n",
    "        \n",
    "    if params['alignment']['nonrigid']['template_method'] == 'image':\n",
    "        template = FOV_images_forAligner[idx_st] \n",
    "    if params['alignment']['nonrigid']['template_method'] == 'sequential':\n",
    "        template = idx_st\n",
    "\n",
    "    aligner = alignment.Alinger(\n",
    "        method=params['alignment']['nonrigid']['method'],\n",
    "        kwargs_method=params['alignment']['nonrigid']['kwargs_method'],\n",
    "    )\n",
    "\n",
    "    aligner.register_ROIs(\n",
    "        template=template,\n",
    "        FOVs=FOV_images_forAligner,\n",
    "        ROIs=data.spatialFootprints,\n",
    "        template_method=params['alignment']['nonrigid']['template_method'],\n",
    "        shifts=shifts,\n",
    "        return_sparse=params['alignment']['nonrigid']['return_sparse'],\n",
    "        normalize=params['alignment']['nonrigid']['normalize'],\n",
    "    );\n",
    "\n",
    "    roicat.visualization.display_toggle_image_stack(aligner.FOVs_aligned)\n",
    "    roicat.visualization.display_toggle_image_stack(aligner.get_ROIsAligned_maxIntensityProjection(), clim=[0,0.03])\n",
    "    roicat.visualization.display_toggle_2channel_image_stack(aligner.flows)\n",
    "\n",
    "    toc['alignment'] = time.time() - tic\n",
    "\n",
    "\n",
    "    # Blur ROIs (optional)\n",
    "    blurrer = blurring.ROI_Blurrer(\n",
    "        frame_shape=(data.FOV_height, data.FOV_width),\n",
    "        kernel_halfWidth=params['blurring']['kernel_halfWidth'],\n",
    "        plot_kernel=params['blurring']['plot_kernel'],\n",
    "    )\n",
    "\n",
    "    blurrer.blur_ROIs(\n",
    "        spatialFootprints=aligner.ROIs_aligned,\n",
    "    )\n",
    "\n",
    "    # roicat.visualization.display_toggle_image_stack(blurrer.get_ROIsBlurred_maxIntensityProjection())\n",
    "\n",
    "    toc['blur'] = time.time() - tic\n",
    "\n",
    "\n",
    "    # Neural network embedding distances\n",
    "    roinet = roicat.ROInet.ROInet_embedder(\n",
    "        device=params['ROInet']['device'],\n",
    "        dir_networkFiles=params['ROInet']['dir_networkFiles'],\n",
    "        download_method=params['ROInet']['download_method'],\n",
    "        download_url=params['ROInet']['download_url'],\n",
    "        download_hash=params['ROInet']['download_hash'],\n",
    "        forward_pass_version=params['ROInet']['forward_pass_version'],\n",
    "        verbose=params['ROInet']['verbose'],\n",
    "    )\n",
    "\n",
    "    roinet.generate_dataloader(\n",
    "        ROI_images=data.ROI_images,\n",
    "        um_per_pixel=params['importing']['um_per_pixel'],\n",
    "        pref_plot=params['ROInet']['pref_plot'],\n",
    "        batchSize_dataloader=params['ROInet']['batchSize_dataloader'],\n",
    "        pinMemory_dataloader=params['ROInet']['pinMemory_dataloader'],\n",
    "        numWorkers_dataloader=mp.cpu_count(),\n",
    "        persistentWorkers_dataloader=params['ROInet']['persistentWorkers_dataloader'],\n",
    "        prefetchFactor_dataloader=params['ROInet']['prefetchFactor_dataloader'],    \n",
    "    );\n",
    "\n",
    "    # roicat.visualization.display_toggle_image_stack(roinet.ROI_images_rs)\n",
    "\n",
    "    roinet.generate_latents();\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    toc['NN'] = time.time() - tic\n",
    "\n",
    "\n",
    "    # Scattering wavelet embedding distances\n",
    "    swt = scatteringWaveletTransformer.SWT(\n",
    "        kwargs_Scattering2D=params['SWT']['kwargs_Scattering2D'], \n",
    "        image_shape=params['importing']['out_height_width'], \n",
    "        device=params['SWT']['device'],\n",
    "    )\n",
    "\n",
    "    swt.transform(ROI_images=np.concatenate(data.ROI_images, axis=0));\n",
    "\n",
    "    toc['SWT'] = time.time() - tic\n",
    "\n",
    "\n",
    "    # Compute similarities\n",
    "    sim = similarity_graph.ROI_graph(\n",
    "        n_workers=params['similarity']['n_workers'],\n",
    "        frame_height=data.FOV_height,\n",
    "        frame_width=data.FOV_width,\n",
    "        block_height=params['similarity']['block_height'],\n",
    "        block_width=params['similarity']['block_width'],\n",
    "        algorithm_nearestNeigbors_spatialFootprints=params['similarity']['algorithm_nearestNeigbors_spatialFootprints'],\n",
    "        verbose=params['similarity']['verbose'],\n",
    "    )\n",
    "\n",
    "    sim.visualize_blocks()\n",
    "\n",
    "    sim.compute_similarity_blockwise(\n",
    "        spatialFootprints=blurrer.ROIs_blurred,\n",
    "        features_NN=roinet.latents,\n",
    "        features_SWT=swt.latents,\n",
    "        ROI_session_bool=data.session_bool,\n",
    "        spatialFootprint_maskPower=params['similarity']['spatialFootprint_maskPower'],\n",
    "    );\n",
    "\n",
    "    sim.make_normalized_similarities(\n",
    "        centers_of_mass=data.centroids,\n",
    "        features_NN=roinet.latents,\n",
    "        features_SWT=swt.latents,\n",
    "        k_max=params['similarity']['normalization']['k_max'],\n",
    "        k_min=params['similarity']['normalization']['k_min'],\n",
    "        algo_NN=params['similarity']['normalization']['algo_NN'],\n",
    "        device=params['similarity']['normalization']['device'],\n",
    "    )\n",
    "\n",
    "    toc['sim'] = time.time() - tic\n",
    "\n",
    "    ## Cluster\n",
    "    clusterer = clustering.Clusterer(\n",
    "        s_sf=sim.s_sf,\n",
    "        s_NN_z=sim.s_NN_z,\n",
    "        s_SWT_z=sim.s_SWT_z,\n",
    "        s_sesh=sim.s_sesh,\n",
    "    )\n",
    "\n",
    "    kwargs_makeConjunctiveDistanceMatrix_best = clusterer.find_optimal_parameters_for_pruning(\n",
    "        n_bins=params['clustering']['auto_pruning']['n_bins'],\n",
    "        find_parameters_automatically=params['clustering']['auto_pruning']['find_parameters_automatically'],\n",
    "        kwargs_findParameters=params['clustering']['auto_pruning']['kwargs_findParameters'],\n",
    "        bounds_findParameters=params['clustering']['auto_pruning']['bounds_findParameters'],\n",
    "        n_jobs_findParameters=params['clustering']['auto_pruning']['n_jobs'],\n",
    "    )\n",
    "\n",
    "    toc['separate_diffSame'] = time.time() - tic\n",
    "\n",
    "    if params['clustering']['plot_pref']:\n",
    "        clusterer.plot_distSame()\n",
    "\n",
    "        clusterer.plot_similarity_relationships(\n",
    "            plots_to_show=[1,2,3], \n",
    "            max_samples=100000, \n",
    "            kwargs_scatter={'s':1, 'alpha':0.2},\n",
    "            kwargs_makeConjunctiveDistanceMatrix=kwargs_makeConjunctiveDistanceMatrix_best,\n",
    "        );\n",
    "\n",
    "    clusterer.make_pruned_similarity_graphs(\n",
    "        kwargs_makeConjunctiveDistanceMatrix=kwargs_makeConjunctiveDistanceMatrix_best,\n",
    "        stringency=params['clustering']['stringency'],\n",
    "    )\n",
    "\n",
    "    if params['clustering']['method']=='hungarian' or ((params['clustering']['method']=='auto') and (data.n_sessions<8)):\n",
    "        labels = clusterer.fit_sequentialHungarian(\n",
    "            session_bool=data.session_bool,\n",
    "            thresh_cost=params['clustering']['hungarian']['thresh_cost'],\n",
    "            d_conj=None,\n",
    "#             kwargs_makeConjunctiveDistanceMatrix={\n",
    "#             'power_SF': 1.0,\n",
    "#             'power_NN': 1.0,\n",
    "#             'power_SWT': 0.1,\n",
    "#             'p_norm': -2,\n",
    "#             'sig_SF_kwargs': None,\n",
    "#             'sig_NN_kwargs':  {'mu':0, 'b':0.2},\n",
    "#             'sig_SWT_kwargs': {'mu':0, 'b':0.2},\n",
    "#             },\n",
    "        )\n",
    "    else:\n",
    "        labels = clusterer.fit(\n",
    "            session_bool=data.session_bool,\n",
    "            min_cluster_size=params['clustering']['hdbscan']['min_cluster_size'],\n",
    "            cluster_selection_method=params['clustering']['hdbscan']['cluster_selection_method'],\n",
    "            d_clusterMerge=params['clustering']['hdbscan']['d_clusterMerge'],\n",
    "            alpha=params['clustering']['hdbscan']['alpha'],\n",
    "            n_iter_violationCorrection=params['clustering']['hdbscan']['n_iter_violationCorrection'],\n",
    "            d_conj=None,\n",
    "            kwargs_makeConjunctiveDistanceMatrix=kwargs_makeConjunctiveDistanceMatrix_best,\n",
    "            split_intraSession_clusters=params['clustering']['hdbscan']['split_intraSession_clusters'],\n",
    "            d_step=params['clustering']['hdbscan']['d_step'],\n",
    "            discard_failed_pruning=params['clustering']['hdbscan']['discard_failed_pruning'],\n",
    "        )\n",
    "\n",
    "    labels_bySession = [labels[idx] for idx in data.session_bool.T]\n",
    "\n",
    "    toc['clustering'] = time.time() - tic\n",
    "\n",
    "    # visualization\n",
    "    FOV_clusters = roicat.visualization.compute_colored_FOV(\n",
    "        session_bool=data.session_bool,\n",
    "        spatialFootprints=aligner.ROIs_aligned,\n",
    "        FOV_height=data.FOV_height,\n",
    "        FOV_width=data.FOV_width,\n",
    "        labels=labels,\n",
    "        confidence=None,\n",
    "    #     threshold_confidence = 0.99,\n",
    "    )\n",
    "\n",
    "    %matplotlib notebook\n",
    "    roicat.visualization.display_toggle_image_stack(FOV_clusters)\n",
    "\n",
    "    toc['visualize'] = time.time() - tic\n",
    "\n",
    "\n",
    "    ## Save results\n",
    "    dir_save = Path(params['paths']['dir_allOuterFolders']).resolve() if params['paths']['dir_save'] is None else Path(params['paths']['dir_save']).resolve()\n",
    "    filenamePrefix_save = Path(dir_allOuterFolders).name  + params['paths']['pathSuffixToStat'][-100:-9] if params['paths']['filenamePrefix_save'] is None else params['paths']['filenamePrefix_save']\n",
    "    path_save = dir_save / (filenamePrefix_save + '.ROICaT.results' + '.pkl')\n",
    "\n",
    "    ROIs = {\n",
    "        \"ROIs_aligned\": aligner.ROIs_aligned,\n",
    "        \"ROIs_raw\": data.spatialFootprints,\n",
    "        \"frame_height\": data.FOV_height,\n",
    "        \"frame_width\": data.FOV_width,\n",
    "        \"idx_roi_session\": np.where(data.session_bool)[1]\n",
    "    }\n",
    "\n",
    "    results = {\n",
    "        \"UCIDs\": labels,\n",
    "        \"UCIDs_bySession\": labels_bySession,\n",
    "        \"ROIs\": ROIs,\n",
    "        \"params\": params,\n",
    "        \"runTimes\": toc,\n",
    "    }\n",
    "\n",
    "    helpers.pickle_save(\n",
    "        obj=results,\n",
    "        path_save=path_save,\n",
    "        mkdir=True,\n",
    "    )\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    toc['saving'] = time.time() - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d071e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38efc8fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b325908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if params['clustering']['plot_pref']:\n",
    "#     clusterer.plot_distSame()\n",
    "\n",
    "#     clusterer.plot_similarity_relationships(\n",
    "#         plots_to_show=[1,2,3], \n",
    "#         max_samples=100000, \n",
    "#         kwargs_scatter={'s':1, 'alpha':0.2},\n",
    "#         kwargs_makeConjunctiveDistanceMatrix=kwargs_makeConjunctiveDistanceMatrix_best,\n",
    "#     );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import scipy.sparse\n",
    "\n",
    "# import torch_sparse as ts\n",
    "\n",
    "# scipy.sparse.save_npz(\n",
    "#     file=r'/home/rich/Desktop/c_sim.npz',\n",
    "#     matrix=sim.c_sim.tocsr(),\n",
    "#     compressed=True\n",
    "# )\n",
    "# scipy.sparse.save_npz(\n",
    "#     file=r'/home/rich/Desktop/cluster_bool.npz',\n",
    "#     matrix=sim.cluster_bool.tocsr(),\n",
    "#     compressed=True\n",
    "# )\n",
    "# np.save(\n",
    "#     file=r'/home/rich/Desktop/scores.npy',\n",
    "#     arr=sim.scores.numpy(),\n",
    "# )\n",
    "\n",
    "# c_sim = scipy.sparse.load_npz(file=r'/home/rich/Desktop/c_sim.npz').tolil()\n",
    "# cluster_bool = scipy.sparse.load_npz(file=r'/home/rich/Desktop/cluster_bool.npz').tocsr()\n",
    "# scores = torch.as_tensor(np.load(file=r'/home/rich/Desktop/scores.npy'), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d71ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fef490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c4d62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60840e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe27215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c05f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0396ff0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0fe60b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
