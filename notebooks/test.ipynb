{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50622a4e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92846ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conda Environment: rich_clust\n",
      "python version: 3.9.12\n"
     ]
    }
   ],
   "source": [
    "# widen jupyter notebook window\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:95% !important; }</style>\"))\n",
    "\n",
    "# check environment\n",
    "import os\n",
    "print(f'Conda Environment: ' + os.environ['CONDA_DEFAULT_ENV'])\n",
    "\n",
    "from platform import python_version\n",
    "print(f'python version: {python_version()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4eb1fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import natsort\n",
    "\n",
    "import torch\n",
    "# from kymatio.torch import Scattering2D\n",
    "\n",
    "import gc\n",
    "import time\n",
    "import functools\n",
    "import multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b7a5c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_save = '/home/rich/Desktop/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebd0569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'paths': {\n",
    "        'dir_github': r'/media/rich/Home_Linux_partition/github_repos/',  ## directory where ROICat is\n",
    "        'dir_allOuterFolders': r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp16\",  ## directory where directories containing below 'pathSuffixTo...' are\n",
    "        'pathSuffixToStat': 'plane0/stat.npy',  ## path suffix to where the stat.npy file is\n",
    "        'pathSuffixToOps': 'plane0/ops.npy',  ## path suffix to where the ops.npy file is\n",
    "        'dir_save': r'/home/rich/Desktop/',  ## default: None. Directory to save output file to. If None then saves in dir_allOuterFolders.\n",
    "        'filenamePrefix_save': None,  ##  default: None. Filename prefix to save results to. If None then just uses the dir_allOuterFolders.name.\n",
    "    },\n",
    "    'importing': {\n",
    "        'data_verbose': True,  ## default: True. Whether to print out data importing information\n",
    "        'out_height_width': [72, 72],  ## default: [36,36]. Height and width of small cropped output images of each ROI.\n",
    "        'max_footprint_width': 1025,  ## default: 1025. Maximum length of a spatial footprint. If you get an error during importing, try increasing this value.\n",
    "        'type_meanImg': 'meanImgE',  ## default: 'meanImgE'. Type of mean image to use for normalization. This is just a field in the ops.npy file.\n",
    "        'um_per_pixel': 1.0,  ## default: 1.0. Number of microns per pixel for the imaging dataset. Doesn't need to be exact. Used for resizing the ROIs. Check the images of the resized ROIs to tweak.\n",
    "        'new_or_old_suite2p': 'new',  ## default: 'new'. If using suite2p, this specifices whether the stat.npy file is in the old MATLAB format or new Python format.\n",
    "        'images': None,  ## default: None. Set to None if you want to use the images extracted from Suite2p\n",
    "        'import_workers': -1, ## default: -1. Number of workers to use for importing. Set to -1 to use all available workers.\n",
    "    },\n",
    "    'alignment': {\n",
    "        'session_template': 0.5,  ## default: 0.5. Which session to use as a registration template. If input is float (ie 0.0, 0.5, 1.0, etc.), then it is the fractional position of the session to use; if input is int (ie 1, 2, 3), then it is the index of the session to use (0-indexed)\n",
    "        'phaseCorr': {\n",
    "            'freq_highPass': 0.01,  ## default: 0.01. Spatial frequency upper-bound cut-off to use for phase correlation. Spatial frequencies correlations higher than this will be set to zero.\n",
    "            'freq_lowPass': 0.3,  ## default: 0.3. Spatial frequency lower-bound cut-off to use for phase correlation. Spatial frequencies correlations lower than this will be set to zero.\n",
    "        },\n",
    "        'method': 'createOptFlow_DeepFlow',  ## default: 'createOptFlow_DeepFlow'. Method to use for creating optical flow.\n",
    "        'kwargs_method': None,  ## default: None. Keyword arguments to pass to the cv2 optical flow method.\n",
    "        'use_CLAHE': False,  ## default: False. Whether or not to use 'Contrast Limited Adaptive Histogram Equalization'. Useful if params['importing']['type_meanImg'] is not a contrast enhanced image (like 'meanImgE' in Suite2p)\n",
    "        'return_sparse': True,  ## default: True. Whether to return a sparse matrix (True) or a dense matrix (False).\n",
    "        'normalize': True,  ## default: True. If True, normalize the spatial footprints to have a sum of 1.\n",
    "    },\n",
    "    'blurring': {\n",
    "        'kernel_halfWidth': 4.0,  ## default: 2.0. Half-width of the cosine kernel used for blurring. Set value based on how much you think the ROIs move from session to session.\n",
    "        'plot_kernel': False,  ## default: False. Whether to plot the kernel used for blurring.\n",
    "    },\n",
    "    'ROInet': {\n",
    "        'device': 'cuda:0',  ## default: 'cuda:0'. Device to use for ROInet. Recommend using a GPU.\n",
    "        'hash_dict_true': {\n",
    "            'params': ('params.json', '68cf1bd47130f9b6d4f9913f86f0ccaa'),\n",
    "            'model': ('model.py', '61c85529b7aa33e0dfadb31ee253a7e1'),\n",
    "            'state_dict': ('ConvNext_tiny__1_0_best__simCLR.pth', '3287e001ff28d07ada2ae70aa7d0a4da'),\n",
    "        },\n",
    "        'dir_networkFiles': '/home/rich/Downloads/ROInet',  ## local directory where network files are stored\n",
    "        'download_from_gDrive': 'check_local_first',  ## default: 'check_local_first'. Whether to download the network files from Google Drive or to use the local files.\n",
    "        'gDriveID': '1D2Qa-YUNX176Q-wgboGflW0K6un7KYeN',  ## default: '1FCcPZUuOR7xG-hdO6Ei6mx8YnKysVsa8'. Google Drive ID of the network files.\n",
    "        'forward_pass_version': 'latent', # default: 'latent'. Leave as 'latent' for most things. Can be 'latent' (full pass through network), 'head' (output of the head layers), or 'base' (pass through just base layers)\n",
    "        'verbose': True,  ## default: True. Whether to print out ROInet information.\n",
    "        'pref_plot': False,  ## default: False. Whether to plot the ROI and the normalized ROI.\n",
    "        'batchSize_dataloader': 8,  ## default: 8. Number of images to use for each batch.\n",
    "        'pinMemory_dataloader': True,  ## default: True. Whether to pin the memory of the dataloader.\n",
    "        'persistentWorkers_dataloader': True,  ## default: True. Whether to use persistent workers for the dataloader.\n",
    "        'prefetchFactor_dataloader': 2,  ## default: 2. Number of prefetch factors to use for the dataloader.\n",
    "    },\n",
    "    'SWT': {\n",
    "        'kwargs_Scattering2D': {'J': 2, 'L': 2},  ## default: {'J': 2, 'L': 8}. Keyword arguments to pass to the Scattering2D function.\n",
    "        'device': 'cuda:0',  ## default: 'cuda:0'. Device to use for SWT. Recommend using a GPU.\n",
    "    }, \n",
    "    'similarity': {\n",
    "        'spatialFootprint_maskPower': 1.0,  ## default: 1.0. This determines the power to take the ROI mask images to. Higher for more dependent on brightness, lower for more dependent on binary overlap.\n",
    "        'n_workers': -1,  ## default: -1. Number of workers to use for similarity. Set to -1 to use all available workers.\n",
    "        'block_height': 64,  ## default: 64. Maximum height of the FOV block bins to use for pairwise ROI similarity calculations. Use smaller values (16-64) if n_sessions is large (<12), else keep around (64-128)\n",
    "        'block_width': 64,  ## default: 64. Maximum width of the FOV block bins to use for pairwise ROI similarity calculations. Use smaller values (16-64) if n_sessions is large (<12), else keep around (64-128)\n",
    "        'algorithm_nearestNeigbors_spatialFootprints': 'brute',  ## default: 'brute'. Algorithm to use for nearest neighbors.\n",
    "        'verbose': True,  ## default: True. Whether to print out similarity information.\n",
    "        'normalization': {\n",
    "            'k_max': 4000,  ## default: 4000. Maximum kNN distance to use for building a distribution of pairwise similarities for each ROI.\n",
    "            'k_min': 150,  ## default: 150. Set around n_sessions*10. Minimum kNN distance to use for building a distribution of pairwise similarities for each ROI. \n",
    "            'algo_NN': 'kd_tree',\n",
    "        },\n",
    "    },\n",
    "    ## Cluster\n",
    "    'clustering': {\n",
    "        'power_sf': 1,  ## default: 1. Power to which to raise the spatial footprint similarity. Tune by looking at the clusterer.plot_similarity_relationships() plots.\n",
    "        'power_NN': 2,  ## default: 2. Power to which to raise the spatial neural network similarity. Tune by looking at the clusterer.plot_similarity_relationships() plots.\n",
    "        'power_SWT': 0.1,  ## default: 0.1. Power to which to raise the scattering wavelet transform similarity. Tune by looking at the clusterer.plot_similarity_relationships() plots.\n",
    "        'p_norm': -1,  ## default: -1. p-norm to use for the conjunction of the similarity matrices into a single matrix. Higher values are more conjunctive (more like s_sf * s_NN), and lower values are more permissive (more like s_sf + s_NN)\n",
    "        'sig_NN_kwargs': {'mu':0.0, 'b':0.5},  ## default: {'mu':0.0, 'b':0.5}. 'mu' tunes the center, 'b' tunes the sharpness of the sigmoid function applied. Tune by looking at the clusterer.plot_similarity_relationships() plots.\n",
    "        'sig_SWT_kwargs': {'mu':0.0, 'b':0.5},  ## default: {'mu':0.0, 'b':0.5}. 'mu' tunes the center, 'b' tunes the sharpness of the sigmoid function applied. Tune by looking at the clusterer.plot_similarity_relationships() plots.\n",
    "        'n_bins': 100,  ## default: 50. Number of bins to use to create a histogram for determining the cut-off distance for the pairwise distance. Tune by looking at the clusterer.plot_similarity_relationships() plots.\n",
    "        'smoothing_window': 8,  ## default: 8. Number of bins to use as the smoothing window for a savgol_filter. Use smaller distances (3-8) for large datasets (>30k total ROIs), and larger distances (10-20) for smaller datasets.\n",
    "        'plot_pref': True,  ## default: True. Whether or not to plot things related to clustering.\n",
    "        'min_cluster_size': 2,  ## default: 2. Smallest allowable cluster size.\n",
    "        'discard_failed_pruning': True,  ## default: True. Best to leave as True. If the clustering can't find a way to separate clusters with multiple ROIs from the same session, just discard those clusters. Leaving as True shouldn't affect results. Send issue report if it does.\n",
    "    },\n",
    "    'visualization': {\n",
    "        'FOV_threshold_confidence': 0.0,  ## default: 0.0. Threshold for the confidence scores when displaying ROIs.\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e31b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_github = Path(params['paths']['dir_github']).resolve()\n",
    "\n",
    "import sys\n",
    "sys.path.append(str(dir_github))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ROICaT.tracking import data_importing, visualization, alignment, blurring, helpers, ROInet, scatteringWaveletTransformer, similarity_graph, clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5743ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_all = [helpers.deep_update_dict(params, ['paths', 'dir_allOuterFolders'], val) for val in [\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp6_3\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp10\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp11\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp12\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp13\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp16\",\n",
    "# ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6928a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "\n",
    "\n",
    "# Import paths\n",
    "def print_list(l):\n",
    "    for item in l:\n",
    "        print(item)\n",
    "\n",
    "dir_allOuterFolders = Path(params['paths']['dir_allOuterFolders']).resolve()\n",
    "\n",
    "folders_allSessions = natsort.natsorted(helpers.get_dir_contents(dir_allOuterFolders)[0])\n",
    "\n",
    "folders_toUse = folders_allSessions\n",
    "# folders_toUse = list(map(folders_allSessions.__getitem__, [np.arange(1,9, dtype=np.int32)]))\n",
    "\n",
    "\n",
    "# dir_allS2pFolders = [dir_allOuterFolders / folder / 'exp' / 'suite2p' / 'plane0' for folder in folders_toUse]\n",
    "dir_allS2pFolders = [dir_allOuterFolders / folder for folder in folders_toUse]\n",
    "\n",
    "pathSuffixToStat = params['paths']['pathSuffixToStat']\n",
    "pathSuffixToOps = params['paths']['pathSuffixToOps']\n",
    "\n",
    "paths_allStat = np.array([path / pathSuffixToStat for path in dir_allS2pFolders])[:]\n",
    "paths_allOps  = np.array([path / pathSuffixToOps for path in dir_allS2pFolders])[:]\n",
    "\n",
    "print(folders_allSessions)\n",
    "print(folders_toUse)\n",
    "print_list(dir_allS2pFolders)\n",
    "print_list(paths_allStat)\n",
    "\n",
    "\n",
    "#Import data\n",
    "data = data_importing.Data_suite2p(\n",
    "    paths_statFiles=paths_allStat,\n",
    "    paths_opsFiles=paths_allOps,\n",
    "    um_per_pixel=params['importing']['um_per_pixel'],    \n",
    "    new_or_old_suite2p=params['importing']['new_or_old_suite2p'],\n",
    "    verbose=params['importing']['data_verbose'],\n",
    ");\n",
    "\n",
    "data.import_statFiles();\n",
    "\n",
    "data.import_ROI_centeredImages(\n",
    "    out_height_width=params['importing']['out_height_width'],\n",
    "    max_footprint_width=params['importing']['max_footprint_width'],\n",
    ");\n",
    "\n",
    "data.import_FOV_images(\n",
    "    type_meanImg=params['importing']['type_meanImg'],\n",
    "    images=params['importing']['images'],\n",
    ");\n",
    "\n",
    "data.import_ROI_spatialFootprints(workers=params['importing']['import_workers']);\n",
    "\n",
    "# visualization.display_toggle_image_stack(data.FOV_images)\n",
    "\n",
    "\n",
    "# Alignment\n",
    "pcr = alignment.PhaseCorrelation_registration()\n",
    "\n",
    "pcr.set_spectral_mask(\n",
    "    freq_highPass=params['alignment']['phaseCorr']['freq_highPass'],\n",
    "    freq_lowPass=params['alignment']['phaseCorr']['freq_lowPass'],\n",
    "    im_shape=(data.FOV_height, data.FOV_width)\n",
    ")\n",
    "\n",
    "st = params['alignment']['session_template']\n",
    "idx_st = int(st * data.n_sessions) if type(st) is float else st\n",
    "pcr.register(\n",
    "    im_template=data.FOV_images[idx_st],\n",
    "    ims_moving=data.FOV_images\n",
    ");\n",
    "\n",
    "FOV_images = [alignment.clahe(im, grid_size=10, clipLimit=0, normalize=True) for im in pcr.ims_registered[:]] if params['alignment']['use_CLAHE'] else data.FOV_images\n",
    "\n",
    "aligner = alignment.Alinger(\n",
    "    method=params['alignment']['method'],\n",
    "    kwargs_method=params['alignment']['kwargs_method'],\n",
    ")\n",
    "\n",
    "aligner.register_ROIs(\n",
    "    templateFOV=FOV_images[idx_st],\n",
    "    FOVs=FOV_images,\n",
    "    ROIs=data.spatialFootprints,\n",
    "    return_sparse=params['alignment']['return_sparse'],\n",
    "    normalize=params['alignment']['normalize'],\n",
    ");\n",
    "\n",
    "# visualization.display_toggle_image_stack(aligner.FOVs_aligned)\n",
    "# visualization.display_toggle_image_stack(aligner.get_ROIsAligned_maxIntensityProjection())\n",
    "\n",
    "\n",
    "# Blur ROIs (optional)\n",
    "blurrer = blurring.ROI_Blurrer(\n",
    "    frame_shape=(data.FOV_height, data.FOV_width),\n",
    "    kernel_halfWidth=params['blurring']['kernel_halfWidth'],\n",
    "    plot_kernel=params['blurring']['plot_kernel'],\n",
    ")\n",
    "\n",
    "blurrer.blur_ROIs(\n",
    "    spatialFootprints=aligner.ROIs_aligned,\n",
    ")\n",
    "\n",
    "# visualization.display_toggle_image_stack(blurrer.get_ROIsBlurred_maxIntensityProjection())\n",
    "\n",
    "# Neural network embedding distances\n",
    "roinet = ROInet.ROInet_embedder(\n",
    "    device=params['ROInet']['device'],\n",
    "    dir_networkFiles=params['ROInet']['dir_networkFiles'],\n",
    "    download_from_gDrive=params['ROInet']['download_from_gDrive'],\n",
    "    gDriveID=params['ROInet']['gDriveID'],\n",
    "    hash_dict_networkFiles=params['ROInet']['hash_dict_true'],\n",
    "    verbose=params['ROInet']['verbose'],\n",
    ")\n",
    "\n",
    "roinet.generate_dataloader(\n",
    "    ROI_images=data.ROI_images,\n",
    "    um_per_pixel=params['importing']['um_per_pixel'],\n",
    "    pref_plot=params['ROInet']['pref_plot'],\n",
    "    batchSize_dataloader=params['ROInet']['batchSize_dataloader'],\n",
    "    pinMemory_dataloader=params['ROInet']['pinMemory_dataloader'],\n",
    "    numWorkers_dataloader=mp.cpu_count(),\n",
    "    persistentWorkers_dataloader=params['ROInet']['persistentWorkers_dataloader'],\n",
    "    prefetchFactor_dataloader=params['ROInet']['prefetchFactor_dataloader'],    \n",
    ");\n",
    "\n",
    "# visualization.display_toggle_image_stack(roinet.ROI_images_rs)\n",
    "\n",
    "roinet.generate_latents();\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# Scattering wavelet embedding distances\n",
    "swt = scatteringWaveletTransformer.SWT(\n",
    "    kwargs_Scattering2D=params['SWT']['kwargs_Scattering2D'], \n",
    "    image_shape=params['importing']['out_height_width'], \n",
    "    device=params['SWT']['device'],\n",
    ")\n",
    "\n",
    "swt.transform(ROI_images=np.concatenate(data.ROI_images, axis=0));\n",
    "\n",
    "# Compute similarities\n",
    "sim = similarity_graph.ROI_graph(\n",
    "    n_workers=params['similarity']['n_workers'],\n",
    "    frame_height=data.FOV_height,\n",
    "    frame_width=data.FOV_width,\n",
    "    block_height=params['similarity']['block_height'],\n",
    "    block_width=params['similarity']['block_width'],\n",
    "    algorithm_nearestNeigbors_spatialFootprints=params['similarity']['algorithm_nearestNeigbors_spatialFootprints'],\n",
    "    verbose=params['similarity']['verbose'],\n",
    ")\n",
    "\n",
    "sim.visualize_blocks()\n",
    "\n",
    "sim.compute_similarity_blockwise(\n",
    "    spatialFootprints=blurrer.ROIs_blurred,\n",
    "    features_NN=roinet.latents,\n",
    "    features_SWT=swt.latents,\n",
    "    ROI_session_bool=data.sessionID_concat,\n",
    "    spatialFootprint_maskPower=params['similarity']['spatialFootprint_maskPower'],\n",
    ");\n",
    "\n",
    "sim.make_normalized_similarities(\n",
    "    centers_of_mass=data.get_midCoords(),\n",
    "    features_NN=roinet.latents,\n",
    "    features_SWT=swt.latents,\n",
    "    k_max=params['similarity']['normalization']['k_max'],\n",
    "    k_min=params['similarity']['normalization']['k_min'],\n",
    "    algo_NN=params['similarity']['normalization']['algo_NN'],\n",
    ")\n",
    "\n",
    "## Cluster\n",
    "clusterer = clustering.Clusterer()\n",
    "\n",
    "clusterer.make_conjunctive_distance_matrix(\n",
    "    s_sf=sim.s_sf,\n",
    "    s_NN_z=sim.s_NN_z,\n",
    "    s_SWT_z=sim.s_SWT_z,\n",
    "    power_sf=params['clustering']['power_sf'],\n",
    "    power_NN=params['clustering']['power_NN'],\n",
    "    power_SWT=params['clustering']['power_SWT'],\n",
    "    p_norm=params['clustering']['p_norm'],\n",
    "    sig_NN_kwargs=params['clustering']['sig_NN_kwargs'],\n",
    "    sig_SWT_kwargs=params['clustering']['sig_SWT_kwargs'],\n",
    "    plot_sigmoid=params['clustering']['plot_pref'],\n",
    ")\n",
    "\n",
    "# %matplotlib inline\n",
    "if params['clustering']['plot_pref']:\n",
    "    clusterer.plot_similarity_relationships(plots_to_show=[1,2,3])\n",
    "\n",
    "clusterer.find_intermode_cutoff(\n",
    "    n_bins=params['clustering']['n_bins'],\n",
    "    smoothing_window=params['clustering']['smoothing_window'],\n",
    "    plot_pref=params['clustering']['plot_pref'],\n",
    ")\n",
    "\n",
    "\n",
    "labels = clusterer.fit(\n",
    "    session_bool=data.sessionID_concat,\n",
    "    min_cluster_size=params['clustering']['min_cluster_size'],\n",
    "    discard_failed_pruning=params['clustering']['discard_failed_pruning'],\n",
    ");\n",
    "labels_bySession = [labels[idx] for idx in data.sessionID_concat.T]\n",
    "\n",
    "# visualization\n",
    "FOV_clusters = visualization.compute_colored_FOV(\n",
    "    spatialFootprints=aligner.ROIs_aligned,\n",
    "    FOV_height=data.FOV_height,\n",
    "    FOV_width=data.FOV_width,\n",
    "    preds=labels,\n",
    "    confidence=None,\n",
    "    threshold_confidence = params['visualization']['FOV_threshold_confidence'],\n",
    "#     threshold_confidence = 0.99,\n",
    ")\n",
    "\n",
    "%matplotlib notebook\n",
    "visualization.display_toggle_image_stack(FOV_clusters)\n",
    "\n",
    "# visualization\n",
    "FOV_clusters = visualization.compute_colored_FOV(\n",
    "    spatialFootprints=aligner.ROIs_aligned,\n",
    "    FOV_height=data.FOV_height,\n",
    "    FOV_width=data.FOV_width,\n",
    "    preds=labels,\n",
    "    confidence=None,\n",
    "    threshold_confidence = params['visualization']['FOV_threshold_confidence'],\n",
    "#     threshold_confidence = 0.99,\n",
    ")\n",
    "\n",
    "%matplotlib notebook\n",
    "visualization.display_toggle_image_stack(FOV_clusters)\n",
    "\n",
    "## Save results\n",
    "dir_save = Path(params['paths']['dir_allOuterFolders']).resolve() if params['paths']['dir_save'] is None else Path(params['paths']['dir_save']).resolve()\n",
    "filenamePrefix_save = dir_allOuterFolders.name if params['paths']['filenamePrefix_save'] is None else params['paths']['filenamePrefix_save']\n",
    "path_save = dir_save / (filenamePrefix_save + '.ROICaT.results' + '.pkl')\n",
    "\n",
    "ROIs = {\n",
    "    \"ROIs_aligned\": aligner.ROIs_aligned,\n",
    "    \"ROIs_raw\": data.spatialFootprints,\n",
    "    \"frame_height\": data.FOV_height,\n",
    "    \"frame_width\": data.FOV_width,\n",
    "    \"idx_roi_session\": np.where(data.sessionID_concat)[1]\n",
    "}\n",
    "\n",
    "results = {\n",
    "    \"UCIDs\": labels,\n",
    "    \"UCIDs_bySession\": labels_bySession,\n",
    "    \"ROIs\": ROIs,\n",
    "}\n",
    "\n",
    "helpers.simple_save(\n",
    "    obj=results,\n",
    "    filename=path_save,\n",
    "    mkdir=True,\n",
    ")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915fd8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "visualization.display_toggle_image_stack(FOV_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import scipy.sparse\n",
    "\n",
    "# import torch_sparse as ts\n",
    "\n",
    "# scipy.sparse.save_npz(\n",
    "#     file=r'/home/rich/Desktop/c_sim.npz',\n",
    "#     matrix=sim.c_sim.tocsr(),\n",
    "#     compressed=True\n",
    "# )\n",
    "# scipy.sparse.save_npz(\n",
    "#     file=r'/home/rich/Desktop/cluster_bool.npz',\n",
    "#     matrix=sim.cluster_bool.tocsr(),\n",
    "#     compressed=True\n",
    "# )\n",
    "# np.save(\n",
    "#     file=r'/home/rich/Desktop/scores.npy',\n",
    "#     arr=sim.scores.numpy(),\n",
    "# )\n",
    "\n",
    "# c_sim = scipy.sparse.load_npz(file=r'/home/rich/Desktop/c_sim.npz').tolil()\n",
    "# cluster_bool = scipy.sparse.load_npz(file=r'/home/rich/Desktop/cluster_bool.npz').tocsr()\n",
    "# scores = torch.as_tensor(np.load(file=r'/home/rich/Desktop/scores.npy'), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d71ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fef490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c4d62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60840e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d835dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe27215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c05f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0396ff0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a24ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377fa162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2884eabb8096b1e7cd90110c1616d829c56882231962761420acd4f852f6003e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
