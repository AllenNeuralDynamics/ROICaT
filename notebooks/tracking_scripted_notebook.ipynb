{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50622a4e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92846ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conda Environment: rich_clust\n",
      "python version: 3.9.12\n"
     ]
    }
   ],
   "source": [
    "# widen jupyter notebook window\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:95% !important; }</style>\"))\n",
    "\n",
    "# check environment\n",
    "import os\n",
    "print(f'Conda Environment: ' + os.environ['CONDA_DEFAULT_ENV'])\n",
    "\n",
    "from platform import python_version\n",
    "print(f'python version: {python_version()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4eb1fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import natsort\n",
    "\n",
    "import torch\n",
    "# from kymatio.torch import Scattering2D\n",
    "\n",
    "import gc\n",
    "import time\n",
    "import functools\n",
    "import multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a05452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "toc = {}\n",
    "toc['start'] = time.time() - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b7a5c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_save = '/home/rich/Desktop/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc1a828",
   "metadata": {},
   "source": [
    "used for valerio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebd0569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'paths': {\n",
    "#         'dir_github': r'/media/rich/Home_Linux_partition/github_repos/',  ## directory where ROICat is\n",
    "#         'dir_allOuterFolders': r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/20220117_email/Proximal_Dendrites\",  ## directory where directories containing below 'pathSuffixTo...' are\n",
    "#         'pathSuffixToStat': 'stat.npy',  ## path suffix to where the stat.npy file is\n",
    "#         'pathSuffixToOps': 'ops.npy',  ## path suffix to where the ops.npy file is\n",
    "#         'dir_save': r'/home/rich/Desktop/',  ## default: None. Directory to save output file to. If None then saves in dir_allOuterFolders.\n",
    "#         'filenamePrefix_save': None,  ##  default: None. Filename prefix to save results to. If None then just uses the dir_allOuterFolders.name.\n",
    "#     },\n",
    "#     'importing': {\n",
    "#         'data_verbose': True,  ## default: True. Whether to print out data importing information\n",
    "#         'out_height_width': [72, 72],  ## default: [36,36]. Height and width of small cropped output images of each ROI. Check how large your ROIs are in pixels.\n",
    "#         'max_footprint_width': 1025,  ## default: 1025. Maximum length of a spatial footprint. If you get an error during importing, try increasing this value.\n",
    "#         'type_meanImg': 'meanImgE',  ## default: 'meanImgE'. Type of mean image to use for normalization. This is just a field in the ops.npy file.\n",
    "#         'um_per_pixel': 1.0,  ## default: 1.0. Number of microns per pixel for the imaging dataset. Doesn't need to be exact. Used for resizing the ROIs. Check the images of the resized ROIs to tweak.\n",
    "#         'new_or_old_suite2p': 'new',  ## default: 'new'. If using suite2p, this specifices whether the stat.npy file is in the old MATLAB format or new Python format.\n",
    "#         'images': None,  ## default: None. Set to None if you want to use the images extracted from Suite2p\n",
    "#         'import_workers': -1, ## default: -1. Number of workers to use for importing. Set to -1 to use all available workers.\n",
    "#     },\n",
    "#     'alignment': {\n",
    "#         'do_phaseCorrReg': True,  ## default: True. If you are having issues with alignment due to big movements of the FOV. Try setting this to False.\n",
    "#         'session_template': 0.5,  ## default: 0.5. Which session to use as a registration template. If input is float (ie 0.0, 0.5, 1.0, etc.), then it is the fractional position of the session to use; if input is int (ie 1, 2, 3), then it is the index of the session to use (0-indexed)\n",
    "#         'phaseCorr': {\n",
    "#             'freq_highPass': 0.01,  ## default: 0.01. Spatial frequency upper-bound cut-off to use for phase correlation. Units in fraction of the height of the FOV. Spatial frequencies correlations higher than this will be set to zero.\n",
    "#             'freq_lowPass': 0.3,  ## default: 0.3. Spatial frequency lower-bound cut-off to use for phase correlation. Units in fraction of the height of the FOV. Spatial frequencies correlations lower than this will be set to zero.\n",
    "#         },\n",
    "#         'method': 'createOptFlow_DeepFlow',  ## default: 'createOptFlow_DeepFlow'. Method to use for creating optical flow.\n",
    "#         'kwargs_method': None,  ## default: None. Keyword arguments to pass to the cv2 optical flow method.\n",
    "#         'use_CLAHE': False,  ## default: False. Whether or not to use 'Contrast Limited Adaptive Histogram Equalization'. Useful if params['importing']['type_meanImg'] is not a contrast enhanced image (like 'meanImgE' in Suite2p)\n",
    "#         'return_sparse': True,  ## default: True. Whether to return a sparse matrix (True) or a dense matrix (False).\n",
    "#         'normalize': True,  ## default: True. If True, normalize the spatial footprints to have a sum of 1.\n",
    "#     },\n",
    "#     'blurring': {\n",
    "#         'kernel_halfWidth': 5.0,  ## default: 2.0. Half-width of the cosine kernel used for blurring. Set value based on how much you think the ROIs move from session to session.\n",
    "#         'plot_kernel': False,  ## default: False. Whether to plot the kernel used for blurring.\n",
    "#     },\n",
    "#     'ROInet': {\n",
    "#         'device': 'cuda:0',  ## default: 'cuda:0'. Device to use for ROInet. Recommend using a GPU.\n",
    "#         'hash_dict_true': {\n",
    "#             'params': ('params.json', '68cf1bd47130f9b6d4f9913f86f0ccaa'),\n",
    "#             'model': ('model.py', '61c85529b7aa33e0dfadb31ee253a7e1'),\n",
    "#             'state_dict': ('ConvNext_tiny__1_0_best__simCLR.pth', '3287e001ff28d07ada2ae70aa7d0a4da'),\n",
    "#         },\n",
    "#         'dir_networkFiles': '/home/rich/Downloads/ROInet',  ## local directory where network files are stored\n",
    "#         'download_from_gDrive': 'check_local_first',  ## default: 'check_local_first'. Whether to download the network files from Google Drive or to use the local files.\n",
    "#         'gDriveID': '1D2Qa-YUNX176Q-wgboGflW0K6un7KYeN',  ## default: '1FCcPZUuOR7xG-hdO6Ei6mx8YnKysVsa8'. Google Drive ID of the network files.\n",
    "#         'forward_pass_version': 'latent', # default: 'latent'. Leave as 'latent' for most things. Can be 'latent' (full pass through network), 'head' (output of the head layers), or 'base' (pass through just base layers)\n",
    "#         'verbose': True,  ## default: True. Whether to print out ROInet information.\n",
    "#         'pref_plot': False,  ## default: False. Whether to plot the ROI and the normalized ROI.\n",
    "#         'batchSize_dataloader': 8,  ## default: 8. Number of images to use for each batch.\n",
    "#         'pinMemory_dataloader': True,  ## default: True. Whether to pin the memory of the dataloader.\n",
    "#         'persistentWorkers_dataloader': True,  ## default: True. Whether to use persistent workers for the dataloader.\n",
    "#         'prefetchFactor_dataloader': 2,  ## default: 2. Number of prefetch factors to use for the dataloader.\n",
    "#     },\n",
    "#     'SWT': {\n",
    "#         'kwargs_Scattering2D': {'J': 2, 'L': 2},  ## default: {'J': 2, 'L': 2}. Keyword arguments to pass to the kymatio Scattering2D function.\n",
    "#         'device': 'cuda:0',  ## default: 'cuda:0'. Device to use for SWT. Recommend using a GPU.\n",
    "#     }, \n",
    "#     'similarity': {\n",
    "#         'spatialFootprint_maskPower': 0.8,  ## default: 1.0. This determines the power to take the ROI mask images to. Higher for more dependent on brightness, lower for more dependent on binary overlap.\n",
    "#         'n_workers': -1,  ## default: -1. Number of workers to use for similarity. Set to -1 to use all available workers.\n",
    "#         'block_height': 128,  ## default: 64. Maximum height of the FOV block bins to use for pairwise ROI similarity calculations. Use smaller values (16-64) if n_sessions is large (<12), else keep around (64-128)\n",
    "#         'block_width': 128,  ## default: 64. Maximum width of the FOV block bins to use for pairwise ROI similarity calculations. Use smaller values (16-64) if n_sessions is large (<12), else keep around (64-128)\n",
    "#         'algorithm_nearestNeigbors_spatialFootprints': 'brute',  ## default: 'brute'. Algorithm to use for nearest neighbors.\n",
    "#         'verbose': True,  ## default: True. Whether to print out similarity information.\n",
    "#         'normalization': {\n",
    "#             'k_max': 4000,  ## default: 4000. Maximum kNN distance to use for building a distribution of pairwise similarities for each ROI.\n",
    "#             'k_min': 150,  ## default: 150. Set around n_sessions*10. Minimum kNN distance to use for building a distribution of pairwise similarities for each ROI. \n",
    "#             'algo_NN': 'kd_tree',  ## default: 'kd_tree'. Algorithm to use for the nearest neighbors search across positional distances of different ROIs center positions. 'kd_tree' seems to be fastest. See sklearn nearest neighbor documentation for details.\n",
    "#             'device': 'cuda:0',  ## default: 'cpu'. Device to use for the cosine similarity comparisons. Pytorch device.\n",
    "#         },\n",
    "#     },\n",
    "#     ## Cluster\n",
    "#     'clustering': {\n",
    "#         'plot_pref': True,\n",
    "#         'auto_pruning':{\n",
    "#             'n_bins': 50,  ## default: 50. Number of bins to use for estimating the distributions for 'different' and 'same' pairwise similarities\n",
    "#             'find_parameters_automatically': True,  ## default: True. Use optuna automatic parameter searching to find the best values for 'kwargs_makeConjunctiveDistanceMatrix'\n",
    "#             'n_jobs': -1, ## default: 2. Number of jobs to use for the optuna parameter search. Large values or -1 can result in high memory usage.\n",
    "#             'kwargs_findParameters': {\n",
    "#                 'n_patience': 100,\n",
    "#                 'tol_frac': 0.05,\n",
    "#                 'max_trials': 350,\n",
    "#                 'max_duration': 60*10,\n",
    "#                 'verbose': False,\n",
    "#             },\n",
    "#             'bounds_findParameters': {\n",
    "#                 'power_SF': (0.3, 2),\n",
    "#                 'power_NN': (0.2, 2),\n",
    "#                 'power_SWT': (0.1, 1),\n",
    "#                 'p_norm': (-5, 5),\n",
    "#                 'sig_NN_kwargs_mu': (0, 0.5),\n",
    "#                 'sig_NN_kwargs_b': (0.05, 2),\n",
    "#                 'sig_SWT_kwargs_mu': (0, 0.5),\n",
    "#                 'sig_SWT_kwargs_b': (0.05, 2),\n",
    "#             },\n",
    "#         },\n",
    "#         'method': 'auto',  ## default: 'auto'. Can be 'hungarian', 'hdbscan', or 'auto'. If 'auto', then if n_sessions >=8 'hdbscan' will be used.\n",
    "#         'hdbscan':{  ## Used only if 'method' is 'hdbscan'\n",
    "#             'min_cluster_size': 2,  ## default: 2. Best practice is to keep at 2 because issues can occur otherwise. Just manually throw out clusters with fewer ROIs if needed.\n",
    "#             'alpha': 0.999,  ## default: 0.999. Use slightly smaller values (~0.8) if you want bigger less conservative clusters. See hdbscan documentation: https://hdbscan.readthedocs.io/en/latest/parameter_selection.html\n",
    "#             'd_clusterMerge': None,  ## default: None. Distance (mixed conjunctive distance) at which all samples less than this far apart are joined in clusters. If None, then set to mean + 1.0 std of the distribution. See 'cluster_selection_epsilon' in hdbscan documentation: https://hdbscan.readthedocs.io/en/latest/parameter_selection.html\n",
    "#             'cluster_selection_method': 'leaf',  ## default: 'leaf'. 'leaf' is better for smaller homogeneous clusters, 'eom' is better for larger clusters of various densities. See hdbscan documentation: https://hdbscan.readthedocs.io/en/latest/parameter_selection.html\n",
    "#             'split_intraSession_clusters': True,  ## default: True. Splits up clusters with multiple ROIs from the same session into multiple clusters.\n",
    "#             'd_step': 0.03,  ## default: 0.03. Size of steps to take when splitting clusters with multiple ROIs from the same session. Smaller values give higher quality clusters.\n",
    "#             'discard_failed_pruning': True,  ## default: Failsafe. If the splitting doesn't work for whatever reason, then just set all violating clusters to label=-1.\n",
    "#             'n_iter_violationCorrection': 5,  ## default: 5. Number of times to iterate a correcting process to improve clusters. Warning: This can increase run time linearly for large datasets. Typically converges after around 5 iterations. If n_sessions is large (>30), consider increasing.\n",
    "#         },\n",
    "#         'hungarian': {\n",
    "#             'thresh_cost': 0.95, ## default: 0.95. Threshold distance at which all clusters larger than this are discarded. Note that typically no change will occur after values > d_cutoff.\n",
    "#         },\n",
    "#     },\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "3320975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'paths': {\n",
    "        'dir_github': r'/media/rich/Home_Linux_partition/github_repos/',  ## directory where ROICat is\n",
    "        'dir_allOuterFolders': r\"/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY029\",  ## directory where directories containing below 'pathSuffixTo...' are\n",
    "        'pathSuffixToStat': 'stat.npy',  ## path suffix to where the stat.npy file is\n",
    "        'pathSuffixToOps': 'ops.npy',  ## path suffix to where the ops.npy file is\n",
    "        'dir_save': r'/home/rich/Desktop/',  ## default: None. Directory to save output file to. If None then saves in dir_allOuterFolders.\n",
    "        'filenamePrefix_save': None,  ##  default: None. Filename prefix to save results to. If None then just uses the dir_allOuterFolders.name.\n",
    "    },\n",
    "    'importing': {\n",
    "        'data_verbose': True,  ## default: True. Whether to print out data importing information\n",
    "        'out_height_width': [72, 72],  ## default: [36,36]. Height and width of small cropped output images of each ROI. Check how large your ROIs are in pixels.\n",
    "        'max_footprint_width': 1025,  ## default: 1025. Maximum length of a spatial footprint. If you get an error during importing, try increasing this value.\n",
    "        'type_meanImg': 'mimg',  ## default: 'meanImgE'. Type of mean image to use for normalization. This is just a field in the ops.npy file.\n",
    "        'um_per_pixel': 1.0,  ## default: 1.0. Number of microns per pixel for the imaging dataset. Doesn't need to be exact. Used for resizing the ROIs. Check the images of the resized ROIs to tweak.\n",
    "        'new_or_old_suite2p': 'old',  ## default: 'new'. If using suite2p, this specifices whether the stat.npy file is in the old MATLAB format or new Python format.\n",
    "        'images': None,  ## default: None. Set to None if you want to use the images extracted from Suite2p\n",
    "        'import_workers': -1, ## default: -1. Number of workers to use for importing. Set to -1 to use all available workers.\n",
    "    },\n",
    "    'alignment': {\n",
    "        'do_phaseCorrReg': True,  ## default: True. If you are having issues with alignment due to big movements of the FOV. Try setting this to False.\n",
    "        'session_template': 0.5,  ## default: 0.5. Which session to use as a registration template. If input is float (ie 0.0, 0.5, 1.0, etc.), then it is the fractional position of the session to use; if input is int (ie 1, 2, 3), then it is the index of the session to use (0-indexed)\n",
    "        'use_CLAHE': True,  ## default: False. Whether or not to use 'Contrast Limited Adaptive Histogram Equalization'. Useful if params['importing']['type_meanImg'] is not a contrast enhanced image (like 'meanImgE' in Suite2p)\n",
    "        'CLAHE_nGrid': 15,  ## default 10. Unsed if 'use_CLAHE' is False. Defines how many blocks to split the FOV into to normalize the local contrast. See openCV's clahe function. Larger means more CLAHE.\n",
    "        'phaseCorr': {\n",
    "            'freq_highPass': 0.0,  ## default: 0.01. Spatial frequency upper-bound cut-off to use for phase correlation. Units in fraction of the height of the FOV. Spatial frequencies correlations higher than this will be set to zero.\n",
    "            'freq_lowPass': 0.1,  ## default: 0.3. Spatial frequency lower-bound cut-off to use for phase correlation. Units in fraction of the height of the FOV. Spatial frequencies correlations lower than this will be set to zero.\n",
    "            'template_method': 'sequential',  # default: 'sequential'. Either 'sequential' or 'image'. 'sequential' is better if there is significant drift over sessions. If 'sequential', then pcr.register(template=idx) where idx is the index of the image you want the shifts to be relative to. If 'image', then idx is FOVs[idx].\n",
    "        },\n",
    "        'nonrigid':{\n",
    "            'method': 'createOptFlow_DeepFlow',  ## default: 'createOptFlow_DeepFlow'. Method to use for creating optical flow. 'calcOpticalFlowFarneback' and 'createOptFlow_DeepFlow' available.\n",
    "            'kwargs_method': None,  ## default: None. Keyword arguments to pass to the cv2 optical flow method.\n",
    "            'template_method': 'sequential',  ## default: 'image'. Either 'sequential' or 'image'. 'sequential' is better if there is significant drift over sessions.\n",
    "            'return_sparse': True,  ## default: True. Whether to return a sparse matrix (True) or a dense matrix (False).\n",
    "            'normalize': True,  ## default: True. If True, normalize the spatial footprints to have a sum of 1.\n",
    "        },\n",
    "    },\n",
    "    'blurring': {\n",
    "        'kernel_halfWidth': 5.0,  ## default: 2.0. Half-width of the cosine kernel used for blurring. Set value based on how much you think the ROIs move from session to session.\n",
    "        'plot_kernel': False,  ## default: False. Whether to plot the kernel used for blurring.\n",
    "    },\n",
    "    'ROInet': {\n",
    "        'device': 'cuda:0',  ## default: 'cuda:0'. Device to use for ROInet. Recommend using a GPU.\n",
    "        'hash_dict_true': {\n",
    "            'params': ('params.json', '68cf1bd47130f9b6d4f9913f86f0ccaa'),\n",
    "            'model': ('model.py', '61c85529b7aa33e0dfadb31ee253a7e1'),\n",
    "            'state_dict': ('ConvNext_tiny__1_0_best__simCLR.pth', '3287e001ff28d07ada2ae70aa7d0a4da'),\n",
    "        },\n",
    "        'dir_networkFiles': '/home/rich/Downloads/ROInet',  ## local directory where network files are stored\n",
    "        'download_from_gDrive': 'check_local_first',  ## default: 'check_local_first'. Whether to download the network files from Google Drive or to use the local files.\n",
    "        'gDriveID': '1D2Qa-YUNX176Q-wgboGflW0K6un7KYeN',  ## default: '1FCcPZUuOR7xG-hdO6Ei6mx8YnKysVsa8'. Google Drive ID of the network files.\n",
    "        'forward_pass_version': 'latent', # default: 'latent'. Leave as 'latent' for most things. Can be 'latent' (full pass through network), 'head' (output of the head layers), or 'base' (pass through just base layers)\n",
    "        'verbose': True,  ## default: True. Whether to print out ROInet information.\n",
    "        'pref_plot': False,  ## default: False. Whether to plot the ROI and the normalized ROI.\n",
    "        'batchSize_dataloader': 8,  ## default: 8. Number of images to use for each batch.\n",
    "        'pinMemory_dataloader': True,  ## default: True. Whether to pin the memory of the dataloader.\n",
    "        'persistentWorkers_dataloader': True,  ## default: True. Whether to use persistent workers for the dataloader.\n",
    "        'prefetchFactor_dataloader': 2,  ## default: 2. Number of prefetch factors to use for the dataloader.\n",
    "    },\n",
    "    'SWT': {\n",
    "        'kwargs_Scattering2D': {'J': 2, 'L': 2},  ## default: {'J': 2, 'L': 2}. Keyword arguments to pass to the kymatio Scattering2D function.\n",
    "        'device': 'cuda:0',  ## default: 'cuda:0'. Device to use for SWT. Recommend using a GPU.\n",
    "    }, \n",
    "    'similarity': {\n",
    "        'spatialFootprint_maskPower': 0.8,  ## default: 1.0. This determines the power to take the ROI mask images to. Higher for more dependent on brightness, lower for more dependent on binary overlap.\n",
    "        'n_workers': -1,  ## default: -1. Number of workers to use for similarity. Set to -1 to use all available workers.\n",
    "        'block_height': 128,  ## default: 64. Maximum height of the FOV block bins to use for pairwise ROI similarity calculations. Use smaller values (16-64) if n_sessions is large (<12), else keep around (64-128)\n",
    "        'block_width': 128,  ## default: 64. Maximum width of the FOV block bins to use for pairwise ROI similarity calculations. Use smaller values (16-64) if n_sessions is large (<12), else keep around (64-128)\n",
    "        'algorithm_nearestNeigbors_spatialFootprints': 'brute',  ## default: 'brute'. Algorithm to use for nearest neighbors.\n",
    "        'verbose': True,  ## default: True. Whether to print out similarity information.\n",
    "        'normalization': {\n",
    "            'k_max': 4000,  ## default: 4000. Maximum kNN distance to use for building a distribution of pairwise similarities for each ROI.\n",
    "            'k_min': 150,  ## default: 150. Set around n_sessions*10. Minimum kNN distance to use for building a distribution of pairwise similarities for each ROI. \n",
    "            'algo_NN': 'kd_tree',  ## default: 'kd_tree'. Algorithm to use for the nearest neighbors search across positional distances of different ROIs center positions. 'kd_tree' seems to be fastest. See sklearn nearest neighbor documentation for details.\n",
    "            'device': 'cuda:0',  ## default: 'cpu'. Device to use for the cosine similarity comparisons. Pytorch device.\n",
    "        },\n",
    "    },\n",
    "    ## Cluster\n",
    "    'clustering': {\n",
    "        'plot_pref': True,\n",
    "        'auto_pruning':{\n",
    "            'n_bins': 50,  ## default: 50. Number of bins to use for estimating the distributions for 'different' and 'same' pairwise similarities\n",
    "            'find_parameters_automatically': True,  ## default: True. Use optuna automatic parameter searching to find the best values for 'kwargs_makeConjunctiveDistanceMatrix'\n",
    "            'n_jobs': -1, ## default: 2. Number of jobs to use for the optuna parameter search. Large values or -1 can result in high memory usage.\n",
    "            'kwargs_findParameters': {\n",
    "                'n_patience': 100,\n",
    "                'tol_frac': 0.05,\n",
    "                'max_trials': 350,\n",
    "                'max_duration': 60*10,\n",
    "                'verbose': False,\n",
    "            },\n",
    "            'bounds_findParameters': {\n",
    "                'power_SF': (0.3, 2),\n",
    "                'power_NN': (0.2, 2),\n",
    "                'power_SWT': (0.1, 1),\n",
    "                'p_norm': (-5, 5),\n",
    "                'sig_NN_kwargs_mu': (0, 0.5),\n",
    "                'sig_NN_kwargs_b': (0.05, 2),\n",
    "                'sig_SWT_kwargs_mu': (0, 0.5),\n",
    "                'sig_SWT_kwargs_b': (0.05, 2),\n",
    "            },\n",
    "        },\n",
    "        'method': 'auto',  ## default: 'auto'. Can be 'hungarian', 'hdbscan', or 'auto'. If 'auto', then if n_sessions >=8 'hdbscan' will be used.\n",
    "        'hdbscan':{  ## Used only if 'method' is 'hdbscan'\n",
    "            'min_cluster_size': 2,  ## default: 2. Best practice is to keep at 2 because issues can occur otherwise. Just manually throw out clusters with fewer ROIs if needed.\n",
    "            'alpha': 0.999,  ## default: 0.999. Use slightly smaller values (~0.8) if you want bigger less conservative clusters. See hdbscan documentation: https://hdbscan.readthedocs.io/en/latest/parameter_selection.html\n",
    "            'd_clusterMerge': None,  ## default: None. Distance (mixed conjunctive distance) at which all samples less than this far apart are joined in clusters. If None, then set to mean + 1.0 std of the distribution. See 'cluster_selection_epsilon' in hdbscan documentation: https://hdbscan.readthedocs.io/en/latest/parameter_selection.html\n",
    "            'cluster_selection_method': 'leaf',  ## default: 'leaf'. 'leaf' is better for smaller homogeneous clusters, 'eom' is better for larger clusters of various densities. See hdbscan documentation: https://hdbscan.readthedocs.io/en/latest/parameter_selection.html\n",
    "            'split_intraSession_clusters': True,  ## default: True. Splits up clusters with multiple ROIs from the same session into multiple clusters.\n",
    "            'd_step': 0.03,  ## default: 0.03. Size of steps to take when splitting clusters with multiple ROIs from the same session. Smaller values give higher quality clusters.\n",
    "            'discard_failed_pruning': True,  ## default: Failsafe. If the splitting doesn't work for whatever reason, then just set all violating clusters to label=-1.\n",
    "            'n_iter_violationCorrection': 5,  ## default: 5. Number of times to iterate a correcting process to improve clusters. Warning: This can increase run time linearly for large datasets. Typically converges after around 5 iterations. If n_sessions is large (>30), consider increasing.\n",
    "        },\n",
    "        'hungarian': {\n",
    "            'thresh_cost': 0.95, ## default: 0.95. Threshold distance at which all clusters larger than this are discarded. Note that typically no change will occur after values > d_cutoff.\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "26f1e6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "dir_github = Path(params['paths']['dir_github']).resolve()\n",
    "\n",
    "import sys\n",
    "sys.path.append(str(dir_github))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ROICaT.tracking import data_importing, visualization, alignment, blurring, helpers, ROInet, scatteringWaveletTransformer, similarity_graph, clustering"
   ]
  },
  {
   "cell_type": "raw",
   "id": "719b8bd1",
   "metadata": {},
   "source": [
    "params_plane0 = [helpers.deep_update_dict(params, ['paths', 'dir_allOuterFolders'], val) for val in [\n",
    "        r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp6_3\",\n",
    "        r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp10\",\n",
    "        r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp11\",\n",
    "        r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp12\",\n",
    "        r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp13\",\n",
    "        r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp16\",\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "cde5e4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_all = [helpers.deep_update_dict(params, ['paths', 'dir_allOuterFolders'], val) for val in [\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY029\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY030\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY038\",\n",
    "        r\"/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY041\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY044\",\n",
    "]]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00653e0e",
   "metadata": {},
   "source": [
    "params_plane0 = [helpers.deep_update_dict(p, ['paths', 'filenamePrefix_save'], Path(p['paths']['dir_allOuterFolders']).name + '.plane0') for p in params_plane0]\n",
    "\n",
    "\n",
    "params_plane1 = [helpers.deep_update_dict(p, ['paths', 'pathSuffixToStat'], 'plane1/stat.npy') for p in params_plane0]\n",
    "params_plane1 = [helpers.deep_update_dict(p, ['paths', 'pathSuffixToOps'],  'plane1/ops.npy')  for p in params_plane1]\n",
    "\n",
    "params_plane1 = [helpers.deep_update_dict(p, ['paths', 'filenamePrefix_save'], Path(p['paths']['dir_allOuterFolders']).name + '.plane1') for p in params_plane1]\n",
    "\n",
    "\n",
    "params_all = params_plane0 + params_plane1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09ab3cec",
   "metadata": {},
   "source": [
    "params_all = [params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "bc2e1e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20']\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20']\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/0\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/1\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/2\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/3\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/4\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/5\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/6\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/7\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/8\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/9\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/10\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/11\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/12\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/13\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/14\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/15\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/16\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/17\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/18\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/19\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/20\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/0/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/1/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/2/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/3/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/4/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/5/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/6/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/7/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/8/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/9/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/10/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/11/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/12/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/13/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/14/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/15/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/16/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/17/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/18/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/19/stat.npy\n",
      "/media/rich/bigSSD/other lab data/Harvey_lab_ROIs/NOAH_alignment_ground_truth/NY039/20/stat.npy\n",
      "Starting: Importing spatial footprints from stat files\n",
      "Completed: Imported 21 stat files into class as self.statFiles. Total number of ROIs: 9474. Number of ROI from each file: [488, 522, 504, 507, 627, 501, 510, 399, 383, 514, 451, 442, 411, 425, 388, 406, 403, 473, 337, 379, 404]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:00, 45.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 21 spatial footprint files into small centered images in self.ROI_images.\n",
      "Imported 21 FOV images into class as self.FOV_images\n",
      "Importing spatial footprints from stat files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Process ForkProcess-645:\n",
      "Process ForkProcess-626:\n",
      "Process ForkProcess-629:\n",
      "Process ForkProcess-632:\n",
      "Process ForkProcess-628:\n",
      "Process ForkProcess-630:\n",
      "Process ForkProcess-631:\n",
      "Process ForkProcess-627:\n",
      "Process ForkProcess-644:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [395]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m data\u001b[38;5;241m.\u001b[39mimport_ROI_centeredImages(\n\u001b[1;32m     47\u001b[0m     out_height_width\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimporting\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout_height_width\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     48\u001b[0m     max_footprint_width\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimporting\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_footprint_width\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     49\u001b[0m );\n\u001b[1;32m     51\u001b[0m data\u001b[38;5;241m.\u001b[39mimport_FOV_images(\n\u001b[1;32m     52\u001b[0m     type_meanImg\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimporting\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype_meanImg\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     53\u001b[0m     images\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimporting\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     54\u001b[0m );\n\u001b[0;32m---> 56\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_ROI_spatialFootprints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimporting\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimport_workers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# visualization.display_toggle_image_stack(data.FOV_images)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m toc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimport_data\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m tic\n",
      "File \u001b[0;32m/media/rich/Home_Linux_partition/github_repos/ROICaT/tracking/data_importing.py:259\u001b[0m, in \u001b[0;36mData_suite2p.import_ROI_spatialFootprints\u001b[0;34m(self, frame_height_width, dtype, workers)\u001b[0m\n\u001b[1;32m    257\u001b[0m     workers \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mcpu_count()\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m workers \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspatialFootprints \u001b[38;5;241m=\u001b[39m \u001b[43mhelpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimple_multiprocessing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_helper_populate_sf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_roi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mframe_height_width\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatFiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43misInt\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshifts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspatialFootprints \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    266\u001b[0m         _helper_populate_sf(\n\u001b[1;32m    267\u001b[0m             n_roi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_roi[ii], \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m             shifts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshifts[ii]\n\u001b[1;32m    273\u001b[0m         ) \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n), mininterval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m)]\n",
      "File \u001b[0;32m/media/rich/Home_Linux_partition/github_repos/ROICaT/tracking/helpers.py:101\u001b[0m, in \u001b[0;36msimple_multiprocessing\u001b[0;34m(func, args, workers)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimple_multiprocessing\u001b[39m(func, args, workers):\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor(workers) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 101\u001b[0m         res \u001b[38;5;241m=\u001b[39m ex\u001b[38;5;241m.\u001b[39mmap(func, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(res)\n",
      "File \u001b[0;32m/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/concurrent/futures/_base.py:637\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/concurrent/futures/process.py:740\u001b[0m, in \u001b[0;36mProcessPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor_manager_thread_wakeup\u001b[38;5;241m.\u001b[39mwakeup()\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor_manager_thread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m wait:\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_executor_manager_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;66;03m# To reduce the risk of opening too many files, remove references to\u001b[39;00m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;66;03m# objects that use file descriptors.\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor_manager_thread \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/threading.py:1053\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1053\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/threading.py:1073\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1073\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1074\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1075\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "for params in params_all:\n",
    "    # %matplotlib notebook\n",
    "\n",
    "\n",
    "    # Import paths\n",
    "    def print_list(l):\n",
    "        for item in l:\n",
    "            print(item)\n",
    "\n",
    "    dir_allOuterFolders = Path(params['paths']['dir_allOuterFolders']).resolve()\n",
    "\n",
    "    folders_allSessions = natsort.natsorted(helpers.get_dir_contents(dir_allOuterFolders)[0])\n",
    "\n",
    "    folders_toUse = folders_allSessions\n",
    "    # folders_toUse = list(map(folders_allSessions.__getitem__, [np.arange(1,9, dtype=np.int32)]))\n",
    "\n",
    "\n",
    "    # dir_allS2pFolders = [dir_allOuterFolders / folder / 'exp' / 'suite2p' / 'plane0' for folder in folders_toUse]\n",
    "    dir_allS2pFolders = [dir_allOuterFolders / folder for folder in folders_toUse]\n",
    "\n",
    "    pathSuffixToStat = params['paths']['pathSuffixToStat']\n",
    "    pathSuffixToOps = params['paths']['pathSuffixToOps']\n",
    "\n",
    "    paths_allStat = np.array([path / pathSuffixToStat for path in dir_allS2pFolders])[:]\n",
    "    paths_allOps  = np.array([path / pathSuffixToOps for path in dir_allS2pFolders])[:]\n",
    "\n",
    "    print(folders_allSessions)\n",
    "    print(folders_toUse)\n",
    "    print_list(dir_allS2pFolders)\n",
    "    print_list(paths_allStat)\n",
    "\n",
    "    toc['import_paths'] = time.time() - tic\n",
    "\n",
    "\n",
    "    #Import data\n",
    "    data = data_importing.Data_suite2p(\n",
    "        paths_statFiles=paths_allStat,\n",
    "        paths_opsFiles=paths_allOps,\n",
    "        um_per_pixel=params['importing']['um_per_pixel'],    \n",
    "        new_or_old_suite2p=params['importing']['new_or_old_suite2p'],\n",
    "        verbose=params['importing']['data_verbose'],\n",
    "    );\n",
    "\n",
    "    data.import_statFiles();\n",
    "\n",
    "    data.import_ROI_centeredImages(\n",
    "        out_height_width=params['importing']['out_height_width'],\n",
    "        max_footprint_width=params['importing']['max_footprint_width'],\n",
    "    );\n",
    "\n",
    "    data.import_FOV_images(\n",
    "        type_meanImg=params['importing']['type_meanImg'],\n",
    "        images=params['importing']['images'],\n",
    "    );\n",
    "\n",
    "    data.import_ROI_spatialFootprints(workers=params['importing']['import_workers']);\n",
    "\n",
    "    # visualization.display_toggle_image_stack(data.FOV_images)\n",
    "\n",
    "    toc['import_data'] = time.time() - tic\n",
    "\n",
    "\n",
    "    # Alignment\n",
    "    FOV_images = [alignment.clahe(im, grid_size=params['alignment']['CLAHE_nGrid'], clipLimit=np.inf, normalize=True) for im in data.FOV_images[:]] if params['alignment']['use_CLAHE'] else data.FOV_images\n",
    "    st = params['alignment']['session_template']\n",
    "    idx_st = int(st * data.n_sessions) if type(st) is float else st\n",
    "\n",
    "    if params['alignment']['do_phaseCorrReg']:\n",
    "        if params['alignment']['phaseCorr']['template_method'] == 'image':\n",
    "            template = FOV_images[idx_st] \n",
    "        if params['alignment']['phaseCorr']['template_method'] == 'sequential':\n",
    "            template = idx_st\n",
    "            \n",
    "        pcr = alignment.PhaseCorrelation_registration()\n",
    "\n",
    "        pcr.set_spectral_mask(\n",
    "            freq_highPass=params['alignment']['phaseCorr']['freq_highPass'],\n",
    "            freq_lowPass=params['alignment']['phaseCorr']['freq_lowPass'],\n",
    "            im_shape=(data.FOV_height, data.FOV_width)\n",
    "        )\n",
    "\n",
    "        pcr.register(\n",
    "            template=template,\n",
    "            ims_moving=FOV_images,\n",
    "            template_method=params['alignment']['phaseCorr']['template_method'],\n",
    "        );\n",
    "        \n",
    "        FOV_images_forAligner = pcr.ims_registered\n",
    "        shifts = pcr.shifts\n",
    "        \n",
    "        visualization.display_toggle_image_stack(pcr.ims_registered[:])\n",
    "    else:\n",
    "        FOV_images_forAligner = FOV_images\n",
    "        shifts = None\n",
    "        \n",
    "    if params['alignment']['nonrigid']['template_method'] == 'image':\n",
    "        template = FOV_images_forAligner[idx_st] \n",
    "    if params['alignment']['nonrigid']['template_method'] == 'sequential':\n",
    "        template = idx_st\n",
    "\n",
    "    aligner = alignment.Alinger(\n",
    "        method=params['alignment']['nonrigid']['method'],\n",
    "        kwargs_method=params['alignment']['nonrigid']['kwargs_method'],\n",
    "    )\n",
    "\n",
    "    aligner.register_ROIs(\n",
    "        template=template,\n",
    "        FOVs=FOV_images_forAligner,\n",
    "        ROIs=data.spatialFootprints,\n",
    "        template_method=params['alignment']['nonrigid']['template_method'],\n",
    "        shifts=shifts,\n",
    "        return_sparse=params['alignment']['nonrigid']['return_sparse'],\n",
    "        normalize=params['alignment']['nonrigid']['normalize'],\n",
    "    );\n",
    "\n",
    "    visualization.display_toggle_image_stack(aligner.FOVs_aligned)\n",
    "    visualization.display_toggle_image_stack(aligner.get_ROIsAligned_maxIntensityProjection(), clim=[0,0.03])\n",
    "    visualization.display_toggle_2channel_image_stack(aligner.flows)\n",
    "\n",
    "    toc['alignment'] = time.time() - tic\n",
    "\n",
    "\n",
    "    # Blur ROIs (optional)\n",
    "    blurrer = blurring.ROI_Blurrer(\n",
    "        frame_shape=(data.FOV_height, data.FOV_width),\n",
    "        kernel_halfWidth=params['blurring']['kernel_halfWidth'],\n",
    "        plot_kernel=params['blurring']['plot_kernel'],\n",
    "    )\n",
    "\n",
    "    blurrer.blur_ROIs(\n",
    "        spatialFootprints=aligner.ROIs_aligned,\n",
    "    )\n",
    "\n",
    "    # visualization.display_toggle_image_stack(blurrer.get_ROIsBlurred_maxIntensityProjection())\n",
    "\n",
    "    toc['blur'] = time.time() - tic\n",
    "\n",
    "\n",
    "    # Neural network embedding distances\n",
    "    roinet = ROInet.ROInet_embedder(\n",
    "        device=params['ROInet']['device'],\n",
    "        dir_networkFiles=params['ROInet']['dir_networkFiles'],\n",
    "        download_from_gDrive=params['ROInet']['download_from_gDrive'],\n",
    "        gDriveID=params['ROInet']['gDriveID'],\n",
    "        hash_dict_networkFiles=params['ROInet']['hash_dict_true'],\n",
    "        verbose=params['ROInet']['verbose'],\n",
    "    )\n",
    "\n",
    "    roinet.generate_dataloader(\n",
    "        ROI_images=data.ROI_images,\n",
    "        um_per_pixel=params['importing']['um_per_pixel'],\n",
    "        pref_plot=params['ROInet']['pref_plot'],\n",
    "        batchSize_dataloader=params['ROInet']['batchSize_dataloader'],\n",
    "        pinMemory_dataloader=params['ROInet']['pinMemory_dataloader'],\n",
    "        numWorkers_dataloader=mp.cpu_count(),\n",
    "        persistentWorkers_dataloader=params['ROInet']['persistentWorkers_dataloader'],\n",
    "        prefetchFactor_dataloader=params['ROInet']['prefetchFactor_dataloader'],    \n",
    "    );\n",
    "\n",
    "    # visualization.display_toggle_image_stack(roinet.ROI_images_rs)\n",
    "\n",
    "    roinet.generate_latents();\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    toc['NN'] = time.time() - tic\n",
    "\n",
    "\n",
    "    # Scattering wavelet embedding distances\n",
    "    swt = scatteringWaveletTransformer.SWT(\n",
    "        kwargs_Scattering2D=params['SWT']['kwargs_Scattering2D'], \n",
    "        image_shape=params['importing']['out_height_width'], \n",
    "        device=params['SWT']['device'],\n",
    "    )\n",
    "\n",
    "    swt.transform(ROI_images=np.concatenate(data.ROI_images, axis=0));\n",
    "\n",
    "    toc['SWT'] = time.time() - tic\n",
    "\n",
    "\n",
    "    # Compute similarities\n",
    "    # sim = similarity_graph.ROI_graph(\n",
    "    #     n_workers=params['similarity']['n_workers'],\n",
    "    #     frame_height=data.FOV_height,\n",
    "    #     frame_width=data.FOV_width,\n",
    "    #     block_height=params['similarity']['block_height'],\n",
    "    #     block_width=params['similarity']['block_width'],\n",
    "    #     algorithm_nearestNeigbors_spatialFootprints=params['similarity']['algorithm_nearestNeigbors_spatialFootprints'],\n",
    "    #     verbose=params['similarity']['verbose'],\n",
    "    # )\n",
    "    sim = similarity_graph.ROI_graph(\n",
    "        n_workers=params['similarity']['n_workers'],\n",
    "        frame_height=data.FOV_height,\n",
    "        frame_width=data.FOV_width,\n",
    "        block_height=128,\n",
    "        block_width=128,\n",
    "        algorithm_nearestNeigbors_spatialFootprints=params['similarity']['algorithm_nearestNeigbors_spatialFootprints'],\n",
    "        verbose=params['similarity']['verbose'],\n",
    "    )\n",
    "\n",
    "    sim.visualize_blocks()\n",
    "\n",
    "    sim.compute_similarity_blockwise(\n",
    "        spatialFootprints=blurrer.ROIs_blurred,\n",
    "        features_NN=roinet.latents,\n",
    "        features_SWT=swt.latents,\n",
    "        ROI_session_bool=data.sessionID_concat,\n",
    "        spatialFootprint_maskPower=params['similarity']['spatialFootprint_maskPower'],\n",
    "    );\n",
    "\n",
    "    sim.make_normalized_similarities(\n",
    "        centers_of_mass=data.get_midCoords(),\n",
    "        features_NN=roinet.latents,\n",
    "        features_SWT=swt.latents,\n",
    "        k_max=params['similarity']['normalization']['k_max'],\n",
    "        k_min=params['similarity']['normalization']['k_min'],\n",
    "        algo_NN=params['similarity']['normalization']['algo_NN'],\n",
    "        device=params['similarity']['normalization']['device'],\n",
    "    )\n",
    "\n",
    "    toc['sim'] = time.time() - tic\n",
    "\n",
    "    ## Cluster\n",
    "    clusterer = clustering.Clusterer(\n",
    "        s_sf=sim.s_sf,\n",
    "        s_NN_z=sim.s_NN_z,\n",
    "        s_SWT_z=sim.s_SWT_z,\n",
    "        s_sesh=sim.s_sesh,\n",
    "    )\n",
    "\n",
    "    kwargs_makeConjunctiveDistanceMatrix_best = clusterer.find_optimal_parameters_for_pruning(\n",
    "        n_bins=params['clustering']['auto_pruning']['n_bins'],\n",
    "        find_parameters_automatically=params['clustering']['auto_pruning']['find_parameters_automatically'],\n",
    "        kwargs_findParameters=params['clustering']['auto_pruning']['kwargs_findParameters'],\n",
    "        bounds_findParameters=params['clustering']['auto_pruning']['bounds_findParameters'],\n",
    "        n_jobs_findParameters=params['clustering']['auto_pruning']['n_jobs'],\n",
    "    #     fallback_d_cutoff=0.5,\n",
    "    #     plot_pref=True,\n",
    "    )\n",
    "\n",
    "    toc['separate_diffSame'] = time.time() - tic\n",
    "\n",
    "    if params['clustering']['plot_pref']:\n",
    "        clusterer.plot_distSame()\n",
    "\n",
    "        clusterer.plot_similarity_relationships(\n",
    "            plots_to_show=[1,2,3], \n",
    "            max_samples=100000, \n",
    "            kwargs_scatter={'s':1, 'alpha':0.2},\n",
    "            kwargs_makeConjunctiveDistanceMatrix=kwargs_makeConjunctiveDistanceMatrix_best,\n",
    "        );\n",
    "\n",
    "    clusterer.make_pruned_similarity_graphs(\n",
    "        kwargs_makeConjunctiveDistanceMatrix=kwargs_makeConjunctiveDistanceMatrix_best\n",
    "    )\n",
    "\n",
    "    if params['clustering']['method']=='hungarian' or ((params['clustering']['method']=='auto') and (data.n_sessions<8)):\n",
    "        labels = clusterer.fit_sequentialHungarian(\n",
    "            session_bool=data.sessionID_concat,\n",
    "            thresh_cost=params['clustering']['hungarian']['thresh_cost'],\n",
    "            d_conj=None,\n",
    "#             kwargs_makeConjunctiveDistanceMatrix={\n",
    "#             'power_SF': 1.0,\n",
    "#             'power_NN': 1.0,\n",
    "#             'power_SWT': 0.1,\n",
    "#             'p_norm': -2,\n",
    "#             'sig_SF_kwargs': None,\n",
    "#             'sig_NN_kwargs':  {'mu':0, 'b':0.2},\n",
    "#             'sig_SWT_kwargs': {'mu':0, 'b':0.2},\n",
    "#             },\n",
    "        )\n",
    "    else:\n",
    "        labels = clusterer.fit(\n",
    "            session_bool=data.sessionID_concat,\n",
    "            min_cluster_size=params['clustering']['hdbscan']['min_cluster_size'],\n",
    "            cluster_selection_method=params['clustering']['hdbscan']['cluster_selection_method'],\n",
    "            d_clusterMerge=params['clustering']['hdbscan']['d_clusterMerge'],\n",
    "            alpha=params['clustering']['hdbscan']['alpha'],\n",
    "            n_iter_violationCorrection=params['clustering']['hdbscan']['n_iter_violationCorrection'],\n",
    "            d_conj=None,\n",
    "            kwargs_makeConjunctiveDistanceMatrix=kwargs_makeConjunctiveDistanceMatrix_best,\n",
    "            split_intraSession_clusters=params['clustering']['hdbscan']['split_intraSession_clusters'],\n",
    "            d_step=params['clustering']['hdbscan']['d_step'],\n",
    "            discard_failed_pruning=params['clustering']['hdbscan']['discard_failed_pruning'],\n",
    "        )\n",
    "\n",
    "    labels_bySession = [labels[idx] for idx in data.sessionID_concat.T]\n",
    "\n",
    "    toc['clustering'] = time.time() - tic\n",
    "\n",
    "    # visualization\n",
    "    FOV_clusters = visualization.compute_colored_FOV(\n",
    "        boolSessionID=data.sessionID_concat,\n",
    "        spatialFootprints=aligner.ROIs_aligned,\n",
    "        FOV_height=data.FOV_height,\n",
    "        FOV_width=data.FOV_width,\n",
    "        labels=labels,\n",
    "        confidence=None,\n",
    "    #     threshold_confidence = 0.99,\n",
    "    )\n",
    "\n",
    "    %matplotlib notebook\n",
    "    visualization.display_toggle_image_stack(FOV_clusters)\n",
    "\n",
    "    toc['visualize'] = time.time() - tic\n",
    "\n",
    "\n",
    "    ## Save results\n",
    "    dir_save = Path(params['paths']['dir_allOuterFolders']).resolve() if params['paths']['dir_save'] is None else Path(params['paths']['dir_save']).resolve()\n",
    "    filenamePrefix_save = dir_allOuterFolders.name if params['paths']['filenamePrefix_save'] is None else params['paths']['filenamePrefix_save']\n",
    "    path_save = dir_save / (filenamePrefix_save + '.ROICaT.results' + '.pkl')\n",
    "\n",
    "    ROIs = {\n",
    "        \"ROIs_aligned\": aligner.ROIs_aligned,\n",
    "        \"ROIs_raw\": data.spatialFootprints,\n",
    "        \"frame_height\": data.FOV_height,\n",
    "        \"frame_width\": data.FOV_width,\n",
    "        \"idx_roi_session\": np.where(data.sessionID_concat)[1]\n",
    "    }\n",
    "\n",
    "    results = {\n",
    "        \"UCIDs\": labels,\n",
    "        \"UCIDs_bySession\": labels_bySession,\n",
    "        \"ROIs\": ROIs,\n",
    "        \"params\": params,\n",
    "        \"runTimes\": toc,\n",
    "    }\n",
    "\n",
    "    helpers.simple_save(\n",
    "        obj=results,\n",
    "        filename=path_save,\n",
    "        mkdir=True,\n",
    "    )\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    toc['saving'] = time.time() - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d071e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38efc8fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b325908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if params['clustering']['plot_pref']:\n",
    "#     clusterer.plot_distSame()\n",
    "\n",
    "#     clusterer.plot_similarity_relationships(\n",
    "#         plots_to_show=[1,2,3], \n",
    "#         max_samples=100000, \n",
    "#         kwargs_scatter={'s':1, 'alpha':0.2},\n",
    "#         kwargs_makeConjunctiveDistanceMatrix=kwargs_makeConjunctiveDistanceMatrix_best,\n",
    "#     );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import scipy.sparse\n",
    "\n",
    "# import torch_sparse as ts\n",
    "\n",
    "# scipy.sparse.save_npz(\n",
    "#     file=r'/home/rich/Desktop/c_sim.npz',\n",
    "#     matrix=sim.c_sim.tocsr(),\n",
    "#     compressed=True\n",
    "# )\n",
    "# scipy.sparse.save_npz(\n",
    "#     file=r'/home/rich/Desktop/cluster_bool.npz',\n",
    "#     matrix=sim.cluster_bool.tocsr(),\n",
    "#     compressed=True\n",
    "# )\n",
    "# np.save(\n",
    "#     file=r'/home/rich/Desktop/scores.npy',\n",
    "#     arr=sim.scores.numpy(),\n",
    "# )\n",
    "\n",
    "# c_sim = scipy.sparse.load_npz(file=r'/home/rich/Desktop/c_sim.npz').tolil()\n",
    "# cluster_bool = scipy.sparse.load_npz(file=r'/home/rich/Desktop/cluster_bool.npz').tocsr()\n",
    "# scores = torch.as_tensor(np.load(file=r'/home/rich/Desktop/scores.npy'), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d71ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fef490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c4d62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60840e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d835dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe27215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c05f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0396ff0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0fe60b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2884eabb8096b1e7cd90110c1616d829c56882231962761420acd4f852f6003e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
