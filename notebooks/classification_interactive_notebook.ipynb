{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d180220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Move into Files...\n",
    "class Data():\n",
    "    def __init__(\n",
    "        self,\n",
    "        paths_statFiles,\n",
    "        paths_labelFiles=None,\n",
    "        um_per_pixel=1.0,\n",
    "        new_or_old_suite2p='new',\n",
    "        verbose=True \n",
    "                ):\n",
    "        \"\"\"\n",
    "        Initializes the class for importing spatial footprints.\n",
    "        Args:\n",
    "            paths_statFiles (list of str or pathlib.Path):\n",
    "                List of paths to the stat.npy files.\n",
    "                Elements should be one of: str, pathlib.Path,\n",
    "                 list of str or list of pathlib.Path\n",
    "            paths_labelFiles (list of str or pathlib.Path):\n",
    "                Optional. Only used to train a classifier.\n",
    "                List of paths to the label .npy files.\n",
    "                Elements should be one of: str, pathlib.Path,\n",
    "                 list of str or list of pathlib.Path\n",
    "            um_per_pixel (float):\n",
    "                'micrometers per pixel' of the imaging field\n",
    "                  of view.\n",
    "            verbose (bool):\n",
    "                If True, prints results from each function.\n",
    "        \"\"\"\n",
    "\n",
    "        self.paths_stat = fix_paths(paths_statFiles)\n",
    "        if paths_opsFiles is not None:\n",
    "            self.paths_lbl = fix_paths(paths_labelFiles)\n",
    "        else:\n",
    "            self.paths_lbl = None\n",
    "\n",
    "        self.n_sessions = len(self.paths_stat)\n",
    "        self.statFiles = None\n",
    "        self.um_per_pixel = um_per_pixel\n",
    "        self._new_or_old_suite2p = new_or_old_suite2p\n",
    "        self._verbose = verbose\n",
    "        \n",
    "        return\n",
    "    def import_statFiles(self):\n",
    "        \"\"\"\n",
    "        Imports the stats.npy contents into the class.\n",
    "        This method can be called before any other function.\n",
    "\n",
    "        Returns:\n",
    "            self.statFiles (list):\n",
    "                List of imported files. Type depends on sf_type.\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"Starting: Importing spatial footprints from stat files\") if self._verbose else None\n",
    "\n",
    "        self.statFiles = [np.load(path, allow_pickle=True) for path in self.paths_stat]\n",
    "\n",
    "        self.n_roi = [len(stat) for stat in self.statFiles]\n",
    "        self.n_roi_total = sum(self.n_roi)\n",
    "\n",
    "        print(f\"Completed: Imported {len(self.statFiles)} stat files into class as self.statFiles. Total number of ROIs: {self.n_roi_total}. Number of ROI from each file: {self.n_roi}\") if self._verbose else None\n",
    "        \n",
    "#         if Path(path_stat).suffix == '.npz':\n",
    "#             dat = np.load(path_stat)\n",
    "#             images_labeled = scipy.sparse.csr_matrix((dat['data'], dat['indices'], dat['indptr']), shape=dat['shape']).toarray()\n",
    "#             images_labeled = [images_labeled.reshape([-1, 36,36])]\n",
    "\n",
    "#         elif Path(path_stat).suffix == '.npy':\n",
    "#             images_labeled = \\\n",
    "#                 util.import_multiple_stat_files(   \n",
    "#                     paths_statFiles=[path_stat],\n",
    "#                     out_height_width=[36,36],\n",
    "#                     max_footprint_width=241,\n",
    "#                     plot_pref=True\n",
    "#                 )\n",
    "#         else:\n",
    "#             raise ValueError(f'path_stat: {path_stat} is not an npy or npz file.')\n",
    "        \n",
    "        return self.statFiles\n",
    "        \n",
    "    def import_labelFiles(self):\n",
    "        \"\"\"\n",
    "        Imports the FOV images from ops files or user defined\n",
    "         image arrays.\n",
    "\n",
    "        Args:\n",
    "            type_meanImg (str):\n",
    "                Type of the mean image.\n",
    "                References the key in the ops.npy file.\n",
    "                Options are:\n",
    "                    'meanImgE':\n",
    "                        Enhanced mean image.\n",
    "                    'meanImg':\n",
    "                        Mean image.\n",
    "            images (list of np.ndarray):\n",
    "                Optional. If provided, the FOV images are \n",
    "                 defined by these images.\n",
    "                If not provided, the FOV images are defined by\n",
    "                 the ops.npy files from self.paths_ops.\n",
    "                len(images) must be equal to len(self.paths_stat)\n",
    "                Images must be of the same shape.\n",
    "        \n",
    "        Returns:\n",
    "            self.FOV_images (list):\n",
    "                List of FOV images.\n",
    "                Length of the list is the same self.paths_files.\n",
    "                Each element is a numpy.ndarray of shape:\n",
    "                 (n_files, height, width)\n",
    "        \"\"\"\n",
    "        \n",
    "        raw_images = roinet.ROI_images_rs\n",
    "        raw_images_dup = np.concatenate([raw_images for _ in range(len(raw_labels_match))], axis=0)\n",
    "\n",
    "        self.latents = roinet.latents\n",
    "        latents_dup = np.concatenate([latents for _ in range(len(raw_labels_match))], axis=0)\n",
    "\n",
    "        self.labels = classification.squeeze_integers(np.concatenate(raw_labels_match))\n",
    "        assert raw_images_dup.shape[0] == self.labels.shape[0] , 'num images in stat files does not correspond to num labels'\n",
    "\n",
    "        return self.labels\n",
    "\n",
    "\n",
    "    def drop_nan_rois(self):\n",
    "        \n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    def cleaning(self):\n",
    "#         raw_labels = [np.load(path) for path in path_labels]\n",
    "#         # print([_.shape for _ in raw_labels])\n",
    "#         if fig_gen_params['keep_only_matched_labels']:\n",
    "#             consistent_label_idx = np.where(fg.get_consistent_labels(*raw_labels))\n",
    "#             raw_labels_match = [raw_labels[0][consistent_label_idx]]\n",
    "#             images_labeled = [_[consistent_label_idx] for _ in images_labeled]\n",
    "#         else:\n",
    "#         #     raw_labels_match = [raw_labels[0]]\n",
    "#             raw_labels_match = raw_labels\n",
    "#         # print([_.shape for _ in raw_labels2])\n",
    "\n",
    "\n",
    "\n",
    "#         raw_images = roinet.ROI_images_rs\n",
    "#         raw_images_dup = np.concatenate([raw_images for _ in range(len(raw_labels_match))], axis=0)\n",
    "\n",
    "#         latents = roinet.latents\n",
    "#         latents_dup = np.concatenate([latents for _ in range(len(raw_labels_match))], axis=0)\n",
    "\n",
    "#         labels = classification.squeeze_integers(np.concatenate(raw_labels_match))\n",
    "#         assert raw_images_dup.shape[0] == labels.shape[0] , 'num images in stat files does not correspond to num labels'\n",
    "        \n",
    "        return\n",
    "\n",
    "        \n",
    "    def relabeling(self):\n",
    "#         https://github.com/seung-lab/fastremap\n",
    "\n",
    "#         # Relabel values based on relabels definition\n",
    "#         # Used for combining e.g. 4 into 3 via {4: 3}\n",
    "#         new_labels = fg.relabel(labels, relabels)\n",
    "\n",
    "#         # Identify the examples to keep by with labels not in the list \"lbls_to_drop\"\n",
    "#         # E.g. If all label 6s are bad data to not be classified, pass a list of [6]\n",
    "#         keep_tf = fg.get_keep_labels(new_labels, lbls_to_drop)\n",
    "\n",
    "\n",
    "#         # Create a final list of indices that should be kept (for use in filtering both labels and ROI images)\n",
    "#         idx_toKeep = fg.get_keep_entries(keep_tf)\n",
    "\n",
    "#         # Keep only ROI values that are labelled by not dropped classes\n",
    "#         images_labeled_clean = raw_images_dup[idx_toKeep]\n",
    "#         latents_clean = latents_dup[idx_toKeep]\n",
    "#         labels_clean = labels[idx_toKeep]\n",
    "\n",
    "#         # Set lowest label value to 0 and sweeze all other label numbers to be sequential integers\n",
    "#         labels_clean -= labels_clean.min()\n",
    "#         labels_clean = classification.squeeze_integers(labels_clean)\n",
    "\n",
    "#         # \n",
    "#         idx_nne = fg.get_keep_nonnan_entries(images_labeled_clean)\n",
    "#         images_labeled_clean = images_labeled_clean[idx_nne]\n",
    "#         latents_clean = latents_clean[idx_nne]\n",
    "#         labels_clean = labels_clean[idx_nne]\n",
    "            \n",
    "            return\n",
    "\n",
    "    \n",
    "def fix_paths(paths):\n",
    "    \"\"\"\n",
    "    Make sure path_files is a list of pathlib.Path\n",
    "    \n",
    "    Args:\n",
    "        paths (list of str or pathlib.Path or str or pathlib.Path):\n",
    "            Potentially dirty input.\n",
    "            \n",
    "    Returns:\n",
    "        paths (list of pathlib.Path):\n",
    "            List of pathlib.Path\n",
    "    \"\"\"\n",
    "    \n",
    "    if (type(paths) is str) or (type(paths) is pathlib.PosixPath):\n",
    "        paths_files = [Path(paths)]\n",
    "    if type(paths[0]) is str:\n",
    "        paths_files = [Path(path) for path in paths]\n",
    "    if type(paths[0]) is pathlib.PosixPath:\n",
    "        paths_files = paths\n",
    "    else:\n",
    "        raise TypeError(\"path_files must be a list of str or list of pathlib.Path or a str or pathlib.Path\")\n",
    "\n",
    "    return paths_files\n",
    "    \n",
    "    \n",
    "# class ROINet():\n",
    "#     def __init__(self):\n",
    "#         return\n",
    "#         device_dataloader = torch_helpers.set_device(use_GPU=simclr_params_json['useGPU_dataloader'])\n",
    "#         DEVICE = torch_helpers.set_device(use_GPU=simclr_params_json['useGPU_training'])\n",
    "\n",
    "#         # hash_dict_true={\n",
    "#         #             'params': ('params.json', hash_file('/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/debugging/params.json')),\n",
    "#         #             'model': ('model.py', hash_file('/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/debugging/model.py')),\n",
    "#         #             'state_dict': ('ConvNext_tiny__1_0_unfrozen__simCLR.pth', hash_file('/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/debugging/ConvNext_tiny__1_0_unfrozen__simCLR.pth')),\n",
    "#         #         }\n",
    "#         # hash_dict_true={\n",
    "#         #             'params': ('params.json', hash_file('/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/debugging/params.json')),\n",
    "#         #             'model': ('model.py', hash_file('/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/debugging/model.py')),\n",
    "#         #             'state_dict': ('ConvNext_tiny__1_0_best__simCLR.pth', hash_file('/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/debugging/ConvNext_tiny__1_0_best__simCLR.pth')),\n",
    "#         #         }\n",
    "\n",
    "#         ROIne_params = fig_gen_params['ROIne_params']\n",
    "#         if 'hash_dict_true' in fig_gen_params:\n",
    "#             hash_dict_true = fig_gen_params['hash_dict_true']\n",
    "#         else:\n",
    "#             hash_dict_true = {}\n",
    "#         roinet = ROInet.ROInet_embedder(device=DEVICE, hash_dict_networkFiles=hash_dict_true, **ROIne_params)\n",
    "#         # roinet = ROInet.ROInet_embedder(device=DEVICE, hash_dict_networkFiles=hash_dict_true, **ROIne_params)\n",
    "\n",
    "#         ROIne_gen_dataloader_params = fig_gen_params['ROIne_gen_dataloader_params']\n",
    "#         roinet.generate_dataloader(ROI_images=images_labeled, numWorkers_dataloader=mp.cpu_count(), **ROIne_gen_dataloader_params);\n",
    "\n",
    "#         roinet.generate_latents();\n",
    "\n",
    "class Embedder():\n",
    "    def __init__(self):\n",
    "        # Get Embeddings\n",
    "\n",
    "        umap_params = dict(\n",
    "            n_neighbors=30,\n",
    "            n_components=2,\n",
    "            metric='euclidean',\n",
    "            metric_kwds=None,\n",
    "            output_metric='euclidean',\n",
    "            output_metric_kwds=None,\n",
    "            n_epochs=None,\n",
    "            learning_rate=1.0,\n",
    "            init='spectral',\n",
    "            min_dist=0.1,\n",
    "            spread=1.0,\n",
    "            low_memory=True,\n",
    "            n_jobs=-1,\n",
    "            set_op_mix_ratio=1.0,\n",
    "            local_connectivity=1.0,\n",
    "            repulsion_strength=1.0,\n",
    "            negative_sample_rate=5,\n",
    "            transform_queue_size=4.0,\n",
    "            a=None,\n",
    "            b=None,\n",
    "            random_state=None,\n",
    "            angular_rp_forest=False,\n",
    "            target_n_neighbors=-1,\n",
    "            target_metric='categorical',\n",
    "            target_metric_kwds=None,\n",
    "            target_weight=0.5,\n",
    "            transform_seed=42,\n",
    "            transform_mode='embedding',\n",
    "            force_approximation_algorithm=False,\n",
    "            verbose=False,\n",
    "            tqdm_kwds=None,\n",
    "            unique=False,\n",
    "            densmap=False,\n",
    "            dens_lambda=2.0,\n",
    "            dens_frac=0.3,\n",
    "            dens_var_shift=0.1,\n",
    "            output_dens=False,\n",
    "            disconnection_distance=None,\n",
    "            precomputed_knn=(None, None, None),\n",
    "        )\n",
    "\n",
    "        umap = UMAP(**umap_params)\n",
    "        embeddings = umap.fit_transform(features_nn)\n",
    "        return\n",
    "    def fit(self):\n",
    "        return\n",
    "    def transform(self)\n",
    "        return\n",
    "\n",
    "class Classifier():\n",
    "    def __init__(self):\n",
    "        return\n",
    "    def pca(self):\n",
    "#         # PCA\n",
    "#         comp_nn, scores_nn, SVs, EVR_nn = decomposition.torch_pca(features_nn, zscore=False)\n",
    "#         # scores_nn = features_nn\n",
    "\n",
    "#         # Normalize PCA'd Values\n",
    "#         features_norm = torch.cat([_ / torch.std(_, dim=0).mean() for _ in [scores_nn]], dim=1)\n",
    "#         # features_norm = scores_nn\n",
    "        return\n",
    "    \n",
    "\n",
    "class Visualization():\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b84fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db3ae2f7",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97949d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conda Environment: jupyter_launcher\n",
      "python version: 3.8.12\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "# check environment\n",
    "import os\n",
    "print(f'Conda Environment: ' + os.environ['CONDA_DEFAULT_ENV'])\n",
    "\n",
    "from platform import python_version\n",
    "print(f'python version: {python_version()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e36ab5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Version: 1.21.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import importlib.util\n",
    "# import glob\n",
    "# from pathlib import Path\n",
    "# from umap import UMAP\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import sklearn\n",
    "# from sklearn.model_selection import train_test_split, ShuffleSplit, StratifiedShuffleSplit\n",
    "# import scipy.stats\n",
    "# import scipy.signal\n",
    "# from kymatio import Scattering2D\n",
    "# import json\n",
    "import numpy as np\n",
    "# import torchvision\n",
    "# import torch\n",
    "# from tqdm.notebook import tqdm, trange\n",
    "# import sys\n",
    "# import pickle\n",
    "# # import pandas as pd\n",
    "# import shutil\n",
    "# import h5py\n",
    "# import figgen as fg\n",
    "# import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "print('Numpy Version:', np.__version__)\n",
    "# print('TorchVision Version:',torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8673d43",
   "metadata": {},
   "source": [
    "# Import Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c375e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spr(*directory_list):\n",
    "    for dir_num, directory in enumerate(directory_list):\n",
    "        if dir_num == 0:\n",
    "            full_directory = Path(directory)\n",
    "        else:\n",
    "            full_directory = full_directory / directory\n",
    "    return str(full_directory.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13da6238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_list(l):\n",
    "    for item in l:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc7d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_allOuterFolders = Path(r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp16\").resolve()\n",
    "# dir_allOuterFolders = Path(r\"/media/rich/bigSSD/res2p/scanimage data/round 5 experiments/mouse 2_6/just_stat_files\").resolve()\n",
    "\n",
    "folders_allSessions = natsort.natsorted(helpers.get_dir_contents(dir_allOuterFolders)[0])\n",
    "\n",
    "dir_allS2pFolders = [dir_allOuterFolders / folder for folder in folders_allSessions]\n",
    "\n",
    "pathSuffixToStat = 'plane0/stat.npy'\n",
    "pathSuffixToOps = 'plane0/ops.npy'\n",
    "# pathSuffixToStat = 'stat.npy'\n",
    "# pathSuffixToOps = 'ops.npy'\n",
    "\n",
    "paths_allStat = np.array([path / pathSuffixToStat for path in dir_allS2pFolders])[:]\n",
    "paths_allOps  = np.array([path / pathSuffixToOps for path in dir_allS2pFolders])[:]\n",
    "# paths_allStat = np.array([path / pathSuffixToStat for path in dir_allS2pFolders])\n",
    "# paths_allOps  = np.array([path / pathSuffixToOps for path in dir_allS2pFolders])\n",
    "\n",
    "print(f'folder names of all sessions: \\n{folders_allSessions}')\n",
    "print(f'paths to all stat files: \\n{paths_allStat}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d01ca7b",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4179f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_importing.Data_suite2p(\n",
    "    paths_statFiles=paths_allStats,\n",
    "    paths_labelFiles=paths_allLabels,\n",
    "    um_per_pixel=2.0,\n",
    "    new_or_old_suite2p='new',\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "data.import_statFiles();\n",
    "data.import_labelFiles();\n",
    "\n",
    "# data.import_ROI_spatialFootprints(workers=-1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8363c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# From ROICaT\n",
    "visualization.display_toggle_image_stack(np.concatenate(data.ROI_images, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a179d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc['import_data'] = time.time() - tic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719be632",
   "metadata": {},
   "source": [
    "###### Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d1a134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83365f09",
   "metadata": {},
   "source": [
    "# Concatenate / Adjust / Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c6f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42e95e35",
   "metadata": {},
   "source": [
    "# Adjust Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349b4166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "229d75bd",
   "metadata": {},
   "source": [
    "# Drop Non-Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6e98b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "232dd31e",
   "metadata": {},
   "source": [
    "# Neural Network Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d1df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_dict_true = {\n",
    "    'params': ('params.json', '68cf1bd47130f9b6d4f9913f86f0ccaa'),\n",
    "    'model': ('model.py', '61c85529b7aa33e0dfadb31ee253a7e1'),\n",
    "    'state_dict': ('ConvNext_tiny__1_0_best__simCLR.pth', '3287e001ff28d07ada2ae70aa7d0a4da'),\n",
    "}\n",
    "\n",
    "roinet = ROInet.ROInet_embedder(\n",
    "    device='cuda:0',\n",
    "#     dir_networkFiles='/home/rich/Downloads/ROInet',\n",
    "    dir_networkFiles='/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/ROICaT',\n",
    "    \n",
    "#     download_from_gDrive='force_download',\n",
    "#     download_from_gDrive='force_local',\n",
    "    download_from_gDrive='check_local_first',\n",
    "    gDriveID='1D2Qa-YUNX176Q-wgboGflW0K6un7KYeN',\n",
    "    hash_dict_networkFiles=hash_dict_true,\n",
    "#     hash_dict_networkFiles=None,\n",
    "    forward_pass_version='latent',\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "roinet.generate_dataloader(\n",
    "    ROI_images=data.ROI_images,\n",
    "    um_per_pixel=data.um_per_pixel,\n",
    "    pref_plot=False,\n",
    "    batchSize_dataloader=8,\n",
    "    pinMemory_dataloader=True,\n",
    "    numWorkers_dataloader=mp.cpu_count(),\n",
    "    persistentWorkers_dataloader=True,\n",
    "    prefetchFactor_dataloader=2,    \n",
    ");\n",
    "\n",
    "roinet.generate_latents();\n",
    "\n",
    "# roinet.latents\n",
    "# roinet.dataset\n",
    "# roinet.net\n",
    "# roinet.params_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1419d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8a9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc['NN'] = time.time() - tic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1400ea1f",
   "metadata": {},
   "source": [
    "# Relabel CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c40f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "393f0c10",
   "metadata": {},
   "source": [
    "# Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4fc959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e786b7e1",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97205953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # features_nn = torch.cat(tmp_arr, dim=0)\n",
    "\n",
    "# features_nn = latents_clean\n",
    "\n",
    "# # prv_features_nn = features_nn.numpy().copy()\n",
    "\n",
    "# features_nn_z = scipy.stats.zscore(features_nn, axis=0)\n",
    "# features_nn_z = features_nn_z[:, ~np.isnan(features_nn_z[0,:])]\n",
    "# features_nn_z = torch.as_tensor(features_nn_z, dtype=torch.float32)\n",
    "\n",
    "# # # PCA\n",
    "# comp_nn, scores_nn, SVs, EVR_nn = decomposition.torch_pca(features_nn, zscore=False)\n",
    "# # scores_nn = features_nn\n",
    "\n",
    "# # Normalize PCA'd Values\n",
    "# features_norm = torch.cat([_ / torch.std(_, dim=0).mean() for _ in [scores_nn]], dim=1)\n",
    "# # features_norm = scores_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee49aa93",
   "metadata": {},
   "source": [
    "# Train/Holdout Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af582cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train/Holdout Split\n",
    "# features_train, features_holdout, labels_train, labels_holdout = sklearn.model_selection.train_test_split(features_norm, labels_clean[:features_norm.shape[0]], test_size=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071cd712",
   "metadata": {},
   "source": [
    "# Shuffle Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb025cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50f17b9d",
   "metadata": {},
   "source": [
    "# Train'/Val Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd57c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shuffle Split\n",
    "# splitter = ShuffleSplit(n_splits=classifier_n_splits)\n",
    "# all_split_inx = list(splitter.split(features_train))\n",
    "\n",
    "# # # Train'/Val Extract\n",
    "# trainp_X = [features_train[_[0]] for _ in all_split_inx]\n",
    "# val_X = [features_train[_[1]] for _ in all_split_inx]\n",
    "# trainp_y = [labels_train[_[0]] for _ in all_split_inx]\n",
    "# val_y = [labels_train[_[1]] for _ in all_split_inx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca52a09",
   "metadata": {},
   "source": [
    "# Get Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34167e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fdfcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOV_clusters = visualization.compute_colored_FOV(\n",
    "    spatialFootprints=[r.power(0.7) for r in aligner.ROIs_aligned],\n",
    "    FOV_height=data.FOV_height,\n",
    "    FOV_width=data.FOV_width,\n",
    "    boolSessionID=data.sessionID_concat,\n",
    "    labels=labels,\n",
    "    confidence=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38378447",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "visualization.display_toggle_image_stack(\n",
    "    FOV_clusters, \n",
    "#     interpolation='none', \n",
    "#     filternorm=False, \n",
    "#     resample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed4626",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "_, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(counts, 30, range=(0, data.n_sessions+1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a6b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc['visualize'] = time.time() - tic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69e148b",
   "metadata": {},
   "source": [
    "# Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731aa8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep through regularizations for classifier\n",
    "# for ic, c in enumerate(C_toUse):\n",
    "#     cm_trp_lst = []\n",
    "#     cm_val_lst = []\n",
    "\n",
    "#     cm_trp_cnt_lst = []\n",
    "#     cm_val_cnt_lst = []\n",
    "\n",
    "#     acc_trp_lst = []\n",
    "#     acc_val_lst = []\n",
    "\n",
    "#     # Sweep Through Shuffle Splits\n",
    "#     # trp = Train' or train within single Shuffle Split fold\n",
    "#     # val = Validation or test set within single Shuffle Split fold\n",
    "#     for inx_split in trange(len(trainp_X)):\n",
    "#         tmp_trainp_X = trainp_X[inx_split]\n",
    "#         tmp_trainp_y = trainp_y[inx_split]\n",
    "\n",
    "#         tmp_val_X = val_X[inx_split]\n",
    "#         tmp_val_y = val_y[inx_split]\n",
    "\n",
    "#         logreg = fg.fit_classifier_logreg(tmp_trainp_X, tmp_trainp_y, max_iter=logistic_max_iter, C=c)\n",
    "\n",
    "#         cm_trp = fg.cm_classifier_logreg(logreg, tmp_trainp_X, tmp_trainp_y, github_loc=fig_gen_params['github_loc'])\n",
    "#         cm_val = fg.cm_classifier_logreg(logreg, tmp_val_X, tmp_val_y, github_loc=fig_gen_params['github_loc'])\n",
    "\n",
    "#         cm_trp_cnt = fg.cm_classifier_logreg(logreg, tmp_trainp_X, tmp_trainp_y, counts=True, github_loc=fig_gen_params['github_loc'])\n",
    "#         cm_val_cnt = fg.cm_classifier_logreg(logreg, tmp_val_X, tmp_val_y, counts=True, github_loc=fig_gen_params['github_loc'])\n",
    "\n",
    "#         acc_trp = fg.score_classifier_logreg(logreg, tmp_trainp_X, tmp_trainp_y)\n",
    "#         acc_val = fg.score_classifier_logreg(logreg, tmp_val_X, tmp_val_y)\n",
    "\n",
    "#         cm_trp_lst.append(cm_trp)\n",
    "#         cm_val_lst.append(cm_val)\n",
    "\n",
    "#         cm_trp_cnt_lst.append(cm_trp_cnt)\n",
    "#         cm_val_cnt_lst.append(cm_val_cnt)\n",
    "\n",
    "#         acc_trp_lst.append(acc_trp)\n",
    "#         acc_val_lst.append(acc_val)\n",
    "    \n",
    "    \n",
    "#     cm_trp_mn = np.mean(cm_trp_lst,axis=0)\n",
    "#     cm_val_mn = np.mean(cm_val_lst,axis=0)\n",
    "\n",
    "#     cm_trp_cnt_sm = np.sum(cm_trp_cnt_lst,axis=0)\n",
    "#     cm_val_cnt_sm = np.sum(cm_val_cnt_lst,axis=0)\n",
    "\n",
    "#     # Refitting model to all of training / CV data and evaluating on heldout data\n",
    "#     logreg_refit = fg.fit_classifier_logreg(features_train, labels_train, max_iter=logistic_max_iter, C=c)\n",
    "\n",
    "#     cm_tr = fg.cm_classifier_logreg(logreg_refit, features_train, labels_train, counts=False, github_loc=fig_gen_params['github_loc'])\n",
    "#     cm_ho = fg.cm_classifier_logreg(logreg_refit, features_holdout, labels_holdout, counts=False, github_loc=fig_gen_params['github_loc'])\n",
    "\n",
    "#     cm_tr_cnt = fg.cm_classifier_logreg(logreg_refit, features_train, labels_train, counts=True, github_loc=fig_gen_params['github_loc'])\n",
    "#     cm_ho_cnt = fg.cm_classifier_logreg(logreg_refit, features_holdout, labels_holdout, counts=True, github_loc=fig_gen_params['github_loc'])\n",
    "\n",
    "#     acc_tr = fg.score_classifier_logreg(logreg_refit, features_train, labels_train)\n",
    "#     acc_ho = fg.score_classifier_logreg(logreg_refit, features_holdout, labels_holdout)\n",
    "    \n",
    "#     restricted_n_train_results = {}\n",
    "#     for n_train in n_train_to_use:\n",
    "#         print('Saving: n_train',n_train)\n",
    "#         train_size = n_train/features_train.shape[0] if type(n_train) == type(None) and n_train < features_train else None\n",
    "#         print('Saving: train_size',train_size)\n",
    "#         if train_size is not None:\n",
    "#             # Refitting model to n_train data points from training data / and evaluating on heldout data\n",
    "#             sss = StratifiedShuffleSplit(n_splits=1, train_size=train_size)\n",
    "#             train_subset_inx, _ = sss.split(features_train, labels_train)[0]\n",
    "#             features_train_subset, labels_train_subset = features_train[train_subset_inx], labels_train[train_subset_inx]\n",
    "            \n",
    "#             logreg_refit = fg.fit_classifier_logreg(features_train_subset, labels_train_subset, max_iter=logistic_max_iter, C=c)\n",
    "            \n",
    "#             restricted_n_train_results[f'acc_tr_subset_{n_train}'] = fg.score_classifier_logreg(logreg_refit, features_train_subset, labels_train_subset)\n",
    "#             restricted_n_train_results[f'acc_tr_{n_train}'] = fg.score_classifier_logreg(logreg_refit, features_train, labels_train)\n",
    "#             restricted_n_train_results[f'acc_ho_{n_train}'] = fg.score_classifier_logreg(logreg_refit, features_holdout, labels_holdout)\n",
    "    \n",
    "#     with h5py.File(fig_gen_params['h5_out_name'], 'a') as f:\n",
    "#         g = f.create_group(f'creg_{c}')\n",
    "#         g.attrs['acc_tr'] = np.mean(acc_tr)\n",
    "#         g.attrs['acc_trp'] = np.mean(acc_trp_lst)\n",
    "#         g.attrs['acc_val'] = np.mean(acc_val_lst)\n",
    "#         g.attrs['acc_ho'] = np.mean(acc_ho)\n",
    "        \n",
    "#         for n_train in n_train_to_use:\n",
    "#             print('Saving: n_train',n_train)\n",
    "#             train_size = n_train/features_train.shape[0] if type(n_train) == type(None) and n_train < features_train else None\n",
    "#             print('Saving: train_size',train_size)\n",
    "#             if train_size is not None:\n",
    "#                 g.attrs[f'acc_tr_subset_{n_train}'] = restricted_n_train_results[f'acc_tr_subset_{n_train}']\n",
    "#                 g.attrs[f'acc_tr_{n_train}'] = restricted_n_train_results[f'acc_tr_{n_train}']\n",
    "#                 g.attrs[f'acc_ho_{n_train}'] = restricted_n_train_results[f'acc_ho_{n_train}']\n",
    "\n",
    "#         gg = g.create_group(f'cm_prc')\n",
    "\n",
    "#         gg.create_dataset(f'tr', data=cm_tr)\n",
    "#         gg.create_dataset(f'trp', data=cm_trp_mn)\n",
    "#         gg.create_dataset(f'val', data=cm_val_mn)\n",
    "#         gg.create_dataset(f'ho', data=cm_ho)\n",
    "\n",
    "#         gg = g.create_group(f'cm_count')\n",
    "\n",
    "#         gg.create_dataset(f'tr', data=cm_tr_cnt)\n",
    "#         gg.create_dataset(f'trp', data=cm_trp_cnt_sm)\n",
    "#         gg.create_dataset(f'val', data=cm_val_cnt_sm)\n",
    "#         gg.create_dataset(f'ho', data=cm_ho_cnt)\n",
    "\n",
    "#         gg = g.create_group(f'logreg_model')\n",
    "\n",
    "#         gg.create_dataset(f'coef', data=logreg_refit.coef_)\n",
    "#         gg.create_dataset(f'int', data=logreg_refit.intercept_)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019f193b",
   "metadata": {},
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c57700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_save = Path('/home/rich/Desktop/').resolve()\n",
    "dir_save = Path('/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/ROICaT/output/').resolve()\n",
    "name_save = dir_allOuterFolders.name\n",
    "path_save = dir_save / (name_save + '.ROICaT.results' + '.pkl')\n",
    "\n",
    "ROIs = {\n",
    "    \"ROIs_aligned\": aligner.ROIs_aligned,\n",
    "    \"ROIs_raw\": data.spatialFootprints,\n",
    "    \"frame_height\": data.FOV_height,\n",
    "    \"frame_width\": data.FOV_width,\n",
    "    \"idx_roi_session\": np.where(data.sessionID_concat)[1]\n",
    "}\n",
    "\n",
    "results = {\n",
    "    \"UCIDs\": labels,\n",
    "    \"UCIDs_bySession\": labels_bySession,\n",
    "    \"ROIs\": ROIs,\n",
    "}\n",
    "\n",
    "helpers.simple_save(\n",
    "    obj=results,\n",
    "    filename=path_save,\n",
    "    mkdir=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a7b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc['saving'] = time.time() - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0407b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1143fff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep through regularizations for classifier\n",
    "\n",
    "    # Sweep Through Shuffle Splits\n",
    "\n",
    "    # Refitting model to all of training / CV data and evaluating on heldout data\n",
    "\n",
    "            # Refitting model to n_train data points from training data / and evaluating on heldout data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
