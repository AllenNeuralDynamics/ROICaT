{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import math\n",
    "import argparse\n",
    "import pickle\n",
    "import roicat\n",
    "import scipy.sparse\n",
    "from roicat.model_training import simclr_training_helpers as sth\n",
    "\n",
    "path_script = sys.argv[0]\n",
    "directory_data = '/Users/josh/analysis/data/ROICaT/simclr_training'\n",
    "filepath_params = '/Users/josh/analysis/github_repos/ROICaT/roicat/model_training/simclr_params_base.json'\n",
    "directory_save = '/Users/josh/analysis/outputs/ROICaT/simclr_training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Global preferences\n",
    "# device_train = torch_helpers.set_device(use_GPU=params['useGPU_dataloader'])\n",
    "\n",
    "# # Load parameters from JSON\n",
    "# with open(filepath_params) as f:\n",
    "#     dict_params = json.load(f)\n",
    "\n",
    "dict_params = {\n",
    "    'data': {\n",
    "        'um_per_pixel': 1.0,\n",
    "    'nan_to_num': True,\n",
    "    'nan_to_num_val': 0.0,\n",
    "    'verbose': True},\n",
    "    'dataloader': {\n",
    "        'batchSize_dataloader': 1024,\n",
    "    'pinMemory_dataloader': False,\n",
    "    'numWorkers_dataloader': 0,\n",
    "    'persistentWorkers_dataloader': False,\n",
    "    'prefetchFactor_dataloader': 0,\n",
    "    'img_size_out': [224, 224],\n",
    "    'jit_script_transforms': False,\n",
    "    'shuffle_dataloader': True,\n",
    "    'drop_last_dataloader': True,\n",
    "    'verbose': True,\n",
    "    'transforms_invariant': {'Random_occlusion': {'prob': 0.5,\n",
    "        'size': [0.4, 0.45]},\n",
    "    'Scale_image_sum': {'sum_val': 1, 'epsilon': 1e-09, 'min_sub': True},\n",
    "    'AddPoissonNoise': {'scaler_bounds': [1778.27941004, 5623.4132519],\n",
    "        'prob': 0.4,\n",
    "        'base': 1000,\n",
    "        'scaling': 'log'},\n",
    "    'Horizontal_stripe_scale': {'alpha_min_max': [0.5, 1],\n",
    "        'im_size': [36, 36],\n",
    "        'prob': 0.3},\n",
    "    'Horizontal_stripe_shift': {'alpha_min_max': [1, 2],\n",
    "        'im_size': [36, 36],\n",
    "        'prob': 0.3},\n",
    "    'RandomHorizontalFlip': {'p': 0.0},\n",
    "    'RandomAffine': {'degrees': [-15, 15],\n",
    "        'translate': [0.02, 0.02],\n",
    "        'scale': [0.9, 1.1],\n",
    "        'shear': [-2, 2, -2, 2],\n",
    "        'interpolation': 'bilinear',\n",
    "        'fill': 0,\n",
    "        # 'fillcolor': None,\n",
    "        # 'resample': None\n",
    "        },\n",
    "    'AddGaussianNoise': {'mean': 0, 'std': 0.0003, 'prob': 0.4},\n",
    "    'ScaleDynamicRange': {'scaler_bounds': [0, 1], 'epsilon': 1e-09},\n",
    "    'WarpPoints': {'r': [0.1, 0.2],\n",
    "        'cx': [-0.3, 0.3],\n",
    "        'cy': [-0.3, 0.3],\n",
    "        'dx': [-0.1, 0.1],\n",
    "        'dy': [-0.1, 0.1],\n",
    "        'n_warps': 2,\n",
    "        'prob': 0.5,\n",
    "        'img_size_in': [36, 36],\n",
    "        'img_size_out': [224, 224]},\n",
    "    'TileChannels': {'dim': 0, 'n_channels': 3}}},\n",
    "    'model': {'torchvision_model': 'convnext_tiny',\n",
    "    'filepath_model': '/Users/josh/analysis/outputs/ROICaT/simclr_training/models/ConvNext_tiny__1_0_best__simCLR',\n",
    "    'head_pool_method': 'AdaptiveAvgPool2d',\n",
    "    'head_pool_method_kwargs': {'output_size': 1},\n",
    "    'pre_head_fc_sizes': [256],\n",
    "    'post_head_fc_sizes': [128],\n",
    "    'block_to_unfreeze': '5.6',\n",
    "    'n_block_toInclude': 7,\n",
    "    'head_nonlinearity': 'GELU',\n",
    "    'head_nonlinearity_kwargs': {}},\n",
    "    'trainer': {'n_epochs': 9999999,\n",
    "    'device_train': 'cpu',\n",
    "    'inner_batch_size': 256,\n",
    "    'learning_rate': 0.01,\n",
    "    'penalty_orthogonality': 1.0,\n",
    "    'weight_decay': 0.1,\n",
    "    'gamma': 1.0,\n",
    "    'temperature': 0.03,\n",
    "    'l2_alpha': 0.0\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: Importing ROI images\n",
      "Completed: Imported 1 sessions. Each session has [3000] ROIs. Total number of ROIs is 3000. The um_per_pixel is 1.0 um per pixel.\n",
      "Starting: resizing ROIs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh/analysis/github_repos/ROICaT/roicat/ROInet.py:84: UserWarning: ROICaT WARNING: Image(s) with all zeros detected. These can pass through the network, but may give weird results.\n",
      "  warnings.warn('ROICaT WARNING: Image(s) with all zeros detected. These can pass through the network, but may give weird results.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: resizing ROIs\n",
      "Defined image transformations: Sequential(\n",
      "  (0): Random_occlusion(\n",
      "    (rotator): RandomRotation(degrees=[-180.0, 180.0], interpolation=nearest, expand=False, fill=0)\n",
      "  )\n",
      "  (1): Scale_image_sum()\n",
      "  (2): AddPoissonNoise(level_bounds=[1778.27941004, 5623.4132519], prob=0.4)\n",
      "  (3): Horizontal_stripe_scale()\n",
      "  (4): Horizontal_stripe_shift()\n",
      "  (5): RandomHorizontalFlip(p=0.0)\n",
      "  (6): RandomAffine(degrees=[-15.0, 15.0], translate=[0.02, 0.02], scale=[0.9, 1.1], shear=[-2.0, 2.0, -2.0, 2.0], interpolation=bilinear)\n",
      "  (7): AddGaussianNoise(mean=0, std=0.0003, level_bounds=(0.0, 1.0), prob=0.4)\n",
      "  (8): ScaleDynamicRange(scaler_bounds=[0, 1])\n",
      "  (9): WarpPoints(r=[0.1, 0.2], cx=[-0.3, 0.3], cy=[-0.3, 0.3], dx=[-0.1, 0.1], dy=[-0.1, 0.1], n_warps=2, prob=0.5, img_size_in=[36, 36], img_size_out=[224, 224])\n",
      "  (10): TileChannels(dim=0)\n",
      ")\n",
      "Defined dataset\n",
      "Defined dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh/analysis/github_repos/ROICaT/roicat/ROInet.py:251: UserWarning: prefetchFactor_dataloader is ignored when numWorkers_dataloader == 0. Setting numWorkers_dataloader > 0 will allow prefetchFactor_dataloader to be used.\n",
      "  warnings.warn(f'prefetchFactor_dataloader is ignored when numWorkers_dataloader == 0. Setting numWorkers_dataloader > 0 will allow prefetchFactor_dataloader to be used.')\n",
      "/Users/josh/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/josh/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Tiny_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "list_filepaths_data = [os.path.join(directory_data, filename) for filename in os.listdir(directory_data)]\n",
    "\n",
    "# Load data from dir_data into Data object... or load from saved Data object\n",
    "ROI_sparse_all = [scipy.sparse.load_npz(filepath_ROI_images) for filepath_ROI_images in list_filepaths_data]\n",
    "ROI_images = [sf_sparse.toarray().reshape(sf_sparse.shape[0], 36,36).astype(np.float32) for sf_sparse in ROI_sparse_all]\n",
    "\n",
    "data = roicat.data_importing.Data_roicat();\n",
    "data.set_ROI_images(\n",
    "    ROI_images=[ROI_images[0][:3000]],\n",
    "    um_per_pixel=dict_params['data']['um_per_pixel'],\n",
    ")\n",
    "### Data import preferences\n",
    "# params['paths']['path_data_training']\n",
    "\n",
    "\n",
    "# Create dataset / dataloader\n",
    "ROI_images_rs = roicat.ROInet.Resizer_ROI_images(\n",
    "    ROI_images=np.concatenate(data.ROI_images, axis=0),\n",
    "    um_per_pixel=dict_params['data']['um_per_pixel'],\n",
    "    nan_to_num=dict_params['data']['nan_to_num'],\n",
    "    nan_to_num_val=dict_params['data']['nan_to_num_val'],\n",
    "    verbose=dict_params['data']['verbose']\n",
    ").ROI_images_rs\n",
    "### Resizing preferences\n",
    "\n",
    "dataloader_generator = roicat.ROInet.Dataloader_ROInet(\n",
    "    ROI_images_rs,\n",
    "    batchSize_dataloader=dict_params['dataloader']['batchSize_dataloader'],\n",
    "    pinMemory_dataloader=dict_params['dataloader']['pinMemory_dataloader'],\n",
    "    numWorkers_dataloader=dict_params['dataloader']['numWorkers_dataloader'],\n",
    "    persistentWorkers_dataloader=dict_params['dataloader']['persistentWorkers_dataloader'],\n",
    "    prefetchFactor_dataloader=dict_params['dataloader']['prefetchFactor_dataloader'],\n",
    "    transforms=torch.nn.Sequential(\n",
    "        *[roicat.model_training.augmentation.__dict__[key](**params) for key,params in dict_params['dataloader']['transforms_invariant'].items()]\n",
    "    ), # Converting dictionary of transforms to torch.nn.Sequential object\n",
    "    n_transforms=2,\n",
    "    img_size_out=tuple(dict_params['dataloader']['img_size_out']),\n",
    "    jit_script_transforms=dict_params['dataloader']['jit_script_transforms'],\n",
    "    shuffle_dataloader=dict_params['dataloader']['shuffle_dataloader'],\n",
    "    drop_last_dataloader=dict_params['dataloader']['drop_last_dataloader'],\n",
    "    verbose=dict_params['dataloader']['verbose'],\n",
    ")\n",
    "\n",
    "dataloader = dataloader_generator.dataloader\n",
    "image_out_size = list(dataloader_generator.dataset[0][0][0].shape)\n",
    "\n",
    "# Create Model\n",
    "model_container = sth.Simclr_Model(\n",
    "    filepath_model=dict_params['model']['filepath_model'], # Set filepath to/from which to save/load model\n",
    "    base_model=torchvision.models.__dict__[dict_params['model']['torchvision_model']](pretrained=True),\n",
    "    # Freeze base_model\n",
    "    # slice_point=dict_params['model']['slice_point'],\n",
    "    # Slice off the model at the slice_point and only keep the prior blocks\n",
    "    \n",
    "    \n",
    "    # attachment_block=sth.Attachment_Blocks(\n",
    "    head_pool_method=dict_params['model']['head_pool_method'],\n",
    "    head_pool_method_kwargs=dict_params['model']['head_pool_method_kwargs'],\n",
    "    pre_head_fc_sizes=dict_params['model']['pre_head_fc_sizes'],\n",
    "    post_head_fc_sizes=dict_params['model']['post_head_fc_sizes'],\n",
    "    head_nonlinearity=dict_params['model']['head_nonlinearity'],\n",
    "    head_nonlinearity_kwargs=dict_params['model']['head_nonlinearity_kwargs'],\n",
    "    # ),\n",
    "\n",
    "\n",
    "    # Add the attachment blocks to the end of the base_model\n",
    "    block_to_unfreeze=dict_params['model']['block_to_unfreeze'],\n",
    "    n_block_toInclude=dict_params['model']['n_block_toInclude'],\n",
    "    # Unfreeze the model at and beyond the unfreeze_point\n",
    "    image_out_size=image_out_size,\n",
    "    # Set version of the forward pass to use\n",
    "    load_model=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify criterion, optimizer, scheduler, learning rate, etc.\n",
    "trainer = sth.Simclr_Trainer(\n",
    "    dataloader,\n",
    "    model_container,\n",
    "    \n",
    "    n_epochs=dict_params['trainer']['n_epochs'],\n",
    "    device_train=dict_params['trainer']['device_train'],\n",
    "    inner_batch_size=dict_params['trainer']['inner_batch_size'],\n",
    "    learning_rate=dict_params['trainer']['learning_rate'],\n",
    "    penalty_orthogonality=dict_params['trainer']['penalty_orthogonality'],\n",
    "    weight_decay=dict_params['trainer']['weight_decay'],\n",
    "    gamma=dict_params['trainer']['gamma'],\n",
    "    temperature=dict_params['trainer']['temperature'],\n",
    "    l2_alpha=dict_params['trainer']['l2_alpha'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9999999 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh/.local/lib/python3.11/site-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input latents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "Checking ONNX model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9999999 [1:23:58<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.036196023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The outputs from the saved and loaded models are different.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Loop through epochs, batches, etc. if loss becomes NaNs, don't save the network and stop training. Otherwise, save the network as an onnx file.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m##### TODO\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/analysis/github_repos/ROICaT/roicat/model_training/simclr_training_helpers.py:536\u001b[0m, in \u001b[0;36mSimclr_Trainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[39m## save model\u001b[39;00m\n\u001b[0;32m--> 536\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_container\u001b[39m.\u001b[39;49msave_onnx(allow_overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, check_load_onnx_valid\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/analysis/github_repos/ROICaT/roicat/model_training/simclr_training_helpers.py:377\u001b[0m, in \u001b[0;36mSimclr_Model.save_onnx\u001b[0;34m(self, allow_overwrite, check_load_onnx_valid)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[39m# Check the Onnx output against PyTorch\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mmax(np\u001b[39m.\u001b[39mabs(out_torch_original \u001b[39m-\u001b[39m out_torch_loaded)))\n\u001b[0;32m--> 377\u001b[0m \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39mallclose(out_torch_original, out_torch_loaded, atol\u001b[39m=\u001b[39m\u001b[39m1.e-7\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mThe outputs from the saved and loaded models are different.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    378\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSaved ONNX model is valid.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: The outputs from the saved and loaded models are different."
     ]
    }
   ],
   "source": [
    "# Loop through epochs, batches, etc. if loss becomes NaNs, don't save the network and stop training. Otherwise, save the network as an onnx file.\n",
    "##### TODO\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROICaT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
